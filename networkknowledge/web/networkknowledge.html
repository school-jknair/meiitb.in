<!doctype html>
<html>

<head>
<meta charset='utf-8'>
<meta http-equiv='x-ua-compatible' content='ie=edge'>
<link rel="shortcut icon" href="images/formyreference.png" type="image/x-icon">
<title>Computer Network for your reference</title>
</head>

<body>
<pre>
  <a href="" rel="noopener noreferrer">Introduction to Network</a>                                                                                                                                  <cite>ജയകുമാർ നായർ തയ്യാറാക്കിയത്</cite>
  <hr>
  <table border="0" width="100%">
      <tr>
          <td align="middle"><img src="images/computernetworking.jpg" alt="" width="79%" height="60%"></td>
          <td>  
            <b><a href="#id_expansion_cards_details" style="color: rgb(0, 0, 0); text-decoration: none;">x-----------------------------x</a></b>
            <b><a href="#id_cooling_system_details" style="color: rgb(0, 0, 0); text-decoration: none;"> | x-----------------------------x</a></b>
            <b><a href="#id_internet_protocol_details" style="color: rgb(0, 0, 0); text-decoration: none;">Internet Protocol (IP)</a></b>   
            <b><a href="#id_ip_addressing_details" style="color: rgb(0, 0, 0); text-decoration: none;">IP addressing</a></b> 
            <b><a href="#id_ip_subnetting_details" style="color: rgb(0, 0, 0); text-decoration: none;">IP subnetting, troubleshooting IP</a></b> 
            <b><a href="#id_troubleshooting_ip_addressing_details" style="color: rgb(0, 0, 0); text-decoration: none;">Troubleshooting IP Addressing</a></b> 
            <b><a href="#id_ip_routing_details" style="color: rgb(0, 0, 0); text-decoration: none;">IP Routing</a></b> 
            <b><a href="#id_last_details" style="color: rgb(0, 0, 0); text-decoration: none;">######   reach end of the document   ######</a></b>      <b id="id_top_details"></b> 
          </td>
      </tr>
  </table>
<hr>
<b id="id_expansion_cards_details">draft writing started on 3-Apr-2023</b>
<hr>
<b id="id_further_do_details">further do</b>
Ethernet connection = Ethernet stanadard based LAN connection
what is one collision domain
what one broadcast domain
Subnet mask is used to identify the network and host portions of an IP address. The subnet mask contains a series of contiguous 1s followed by a series of contiguous 0s. 
	1s correspond to the network bits
	0s correspond to the host bits
When an IP address is "ANDed" (bitwise logical AND operation) with the subnet mask, the result is the network portion of the IP address
IP address is 192.168.1.100 [ 1-1-0-0-0-0-0-0-1-0-1-0-1-0-0-0-0-0-0-0-0-0-0-1-0-1-1-0-0-1-0-0 ]
subnet mask is 255.255.255.0 [ 1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-0-0-0-0-0-0-0-0 ]

IP address (bitwise logical AND) subnet mask (is) network portion of the IP address

11000000 10101000 00000001 01100100 & 
11111111 11111111 11111111 00000000 = 
11000000 10101000 00000001 00000000 
ie 
192.168.1.100 bitwise logical AND 
255.255.255.0 is 
192.168.1.0

what is contention-based media access method used in Ethernet networks

<b>network</b> means a group
<b>computer network</b> means 2 or more connected computers can share resources like data and application, office machines or an internet connection
these computer interact with each other using a computer Language called <b>binary code</b> which consists of lot of 0 and 1 in a <b>specific order</b> 
<b>LAN</b>(Local Area Network)
<img src="images/1.1.landiagram.jpg" alt="" width="29%" height="60%">
This network span only a particular geographical location like an office building
In general, modern LANs can support hundreds or even thousands of devices, but the actual number of devices that can be connected will depend on the specific network configuration and the hardware and 
software used
It is best to split a big LAN into smaller logical zones known as <b>workgroups</b> to make administration easier 
In a typical business environment, it's good idea to arrange LAN's workgroups along department divisions; like for 
workgroup for Accounting 
workgroup for Sales 
workgroup for Marketing
workgroups can be interconnected using a device named <b>router</b>
common network components
workstations, a powerful computer that have resources to share 
Servers, a powerful computer that have specialized software for managing networks like network operating system. Some of the dedicated server for single tasks are:
  file server
  mail server
  print server 
Hosts, those machines with a identification number
A virtual local area network (VLAN) is a virtualized connection that connects multiple devices and network nodes from different LANs into one logical network. VLAN stands for Virtual Local Area Network, and 
it is a technique used in computer networking to create logical subnetworks within a physical local area network (LAN). The purpose of VLAN is to improve network efficiency, security, and manageability by 
grouping devices into separate broadcast domains, regardless of their physical location. The main purposes of VLANs include:
    Segmentation: VLANs allow network administrators to segment a large LAN into smaller logical networks. Devices within a VLAN can communicate with each other as if they were on the same LAN, but they 
    are isolated from devices in other VLANs. This helps to reduce network congestion and improve overall network performance.
    Security: VLANs can be used to isolate sensitive or critical devices from other devices on the network. This can help prevent unauthorized access and reduce the risk of security breaches. For example, 
    a engineering department's devices can be placed in a separate VLAN from the general employee devices, providing an additional layer of security.
    Broadcast control: In traditional LANs, broadcast traffic is typically sent to all devices in the broadcast domain, which can cause network congestion. With VLANs, broadcast traffic is limited to 
    devices within the same VLAN, reducing unnecessary broadcast traffic and improving network efficiency.
    Ease of management: VLANs allow for easier management of network resources by logically grouping devices based on their function, department, or location. Network administrators can apply consistent 
    policies, such as access control lists (ACLs) and Quality of Service (QoS) settings, to VLANs, making it easier to manage and enforce network policies across the organization.
    Flexibility: VLANs provide flexibility in network design and reconfiguration. Devices can be easily moved between VLANs without physically moving network cables, which makes it easier to adapt to 
    changes in network requirements or device locations.
<img src="images/1.2.vlandiagram.jpg" alt="" width="29%" height="60%">
A WAN is a group of LANs or other networks that communicate with one another. A WAN (wide-area network) is the technology that connects your offices, cloud applications, and cloud storage together. It is 
called a wide-area network because it spans beyond a single building or large campus to include multiple locations spread across a specific geographic area, or even the world. 
<img src="images/1.3.WAN.jpg" alt="" width="19%" height="40%">
The Internet is a global network of interconnected WANs. The word <b>internet</b> is from the word <b>internetwork</b>. 
MAC addresses(hardware address) are used for communication within a LAN, IP addresses are used for communication both within a LAN and across different LANs, including over the Internet
VPN(Virtual Private Network) is a technology that provides a secure and private connection over a public network, such as the Internet, by encrypting data and creating a virtual private tunnel for 
communication between two or more devices. The main purpose of a VPN is to enhance privacy and security by creating a secure communication channel between two or more devices over an untrusted network, 
such as the Internet. Here are some common use cases and purposes of VPNs:
    Secure Remote Access: VPNs are commonly used by remote workers or telecommuters to securely connect to their organization's internal network from outside the office. This allows employees to access 
    company resources, such as files, applications, and databases, securely over the Internet as if they were directly connected to the organization's internal network.
    Protecting Online Privacy: VPNs can be used to encrypt internet traffic and protect the privacy of users' online activities. By routing internet traffic through a VPN server, the user's IP address and 
    location are masked, making it more difficult for websites, advertisers, and other entities to track and monitor their online activities.
    Bypassing Geographical Restrictions: VPNs can be used to bypass geographical restrictions or censorship imposed by governments or content providers. By connecting to a VPN server located in a different 
    country, users can access region-restricted content or services that may not be available in their own country.
    Secure Public Wi-Fi Usage: Public Wi-Fi networks, such as those found in coffee shops, airports, and hotels, are often unsecured and can be vulnerable to eavesdropping and other security threats. Using 
    a VPN on a public Wi-Fi network can encrypt data and protect against potential security risks.
    Enhanced Security for Data Transfer: VPNs can provide an additional layer of security for data transfer between devices, such as between branch offices of an organization or between business 
    partners. VPNs can encrypt data to protect it from unauthorized access or interception during transit.
    Protecting Personal Information: VPNs can be used to encrypt personal information, such as credit card numbers, usernames, and passwords, when using online banking, online shopping, or other sensitive 
    online activities, to protect against potential data breaches or identity theft.
<img src="images/1.4.VPN.jpg" alt="" width="29%" height="40%">
VLAN is a good solution if the host is a part of the network which is physically local 
VPN is a better solution if the host is part of the network which is physically remote 
Peer-to-peer (P2P) and client/server are two different types of networking architectures used in computer networks.
Peer-to-Peer (P2P) Networking:
    In a P2P network, all devices are considered equal and can act as both clients and servers. Each device on the network can share resources, such as files, printers, and services, directly with other 
    devices without relying on a central server. P2P networks do not have a central authority or control, and devices communicate with each other in a decentralized manner. Examples of P2P networking 
    include file sharing applications like BitTorrent and decentralized communication applications like Skype.
    <img src="images/1.5.peertopeer.jpg" alt="" width="19%" height="40%">
Client/Server Networking:
    In a client/server network, there are dedicated servers that provide services, and client devices request and consume these services. Clients are typically end-user devices, such as desktop computers, 
    laptops, tablets, or smartphones, that connect to servers to access resources and services, such as files, databases, email, and web pages. Servers are powerful computers or systems that are responsible 
    for managing and delivering resources and services to clients.
    <img src="images/1.6.clientserver.jpg" alt="" width="19%" height="40%">
Physical topology refers to the physical layout or arrangement of devices and cables in a computer network. It defines how devices are connected to each other and how data flows between them in a 
physical sense. Physical topology is concerned with the actual physical connections and configurations of network devices, such as computers, switches, routers, hubs, and cables, in the network 
infrastructure. Some common physical network topologies:
    Bus Topology: In a bus topology, all devices are connected to a common communication medium, typically a single cable. Each device shares the same communication medium and can communicate with 
    other devices by transmitting data on the shared cable.
    Star Topology: In a star topology, all devices are connected to a central hub or switch. The hub or switch acts as a central point for data communication, and devices communicate with each other 
    through the hub or switch.
    Ring Topology: In a ring topology, devices are connected in a circular loop, where each device is connected to the device next to it, forming a closed loop. Data is transmitted in one direction 
    around the ring, and each device regenerates and passes the data to the next device until it reaches the destination device.
    Mesh Topology: In a mesh topology, devices are interconnected with multiple redundant paths, creating a highly interconnected network. Mesh topologies can be either full mesh, where every device is 
    connected to every other device, or partial mesh, where only some devices have redundant connections.
    Tree (Hierarchical) Topology: In a tree topology, devices are organized in a hierarchical structure, similar to a tree. Devices are connected in multiple levels, with a root device at the top and 
    branches of devices branching out from the root. Devices in the tree topology can communicate with devices in the same branch or with devices in higher or lower branches.
    Hybrid Topology: A hybrid topology is a combination of two or more different topologies. For example, a network can have a combination of star and bus topologies, or a combination of ring and mesh 
    topologies. Hybrid topologies are often used to take advantage of the strengths of different topologies in different parts of a network.
    <img src="images/1.7.physicaltopology.jpg" alt="" width="59%" height="40%">
In a typical network architecture, the <b>network backbone</b> connects different <b>network segments</b> to enable communication between them. 
Network Backbone: The network backbone, also known as the backbone network or simply backbone, refers to the main high-speed, high-capacity communication links that connect different segments or 
subnetworks within a larger network. The backbone is responsible for carrying data traffic between different parts of the network and acts as a central conduit for data transmission. It is typically 
designed to handle high bandwidth and is used to interconnect major network components, such as switches, routers, and servers. The backbone is a critical part of a network infrastructure and is 
typically built with redundant links for high availability and fault tolerance. Some common types of network backbones include:
    Wired Ethernet Backbone: This is the most traditional and widely used type of network backbone. It uses Ethernet cables, such as Cat5e or Cat6 cables, to establish wired connections between 
    network devices, such as switches, routers, and servers. Wired Ethernet backbones are known for their reliability, scalability, and high performance, making them suitable for large networks 
    with high bandwidth requirements.    
    Fiber Optic Backbone: Fiber optic backbones use fiber optic cables to transmit data as pulses of light, allowing for much higher bandwidth and longer distances compared to copper-based Ethernet 
    backbones. Fiber optic backbones are ideal for networks that require long-distance connectivity, high data rates, and immunity to electromagnetic interference (EMI). They are commonly used in 
    large enterprise networks, data centers, and metropolitan area networks (MANs) where high-speed and long-distance connectivity are essential.    
    Wireless Backbone: Wireless backbones use wireless technologies, such as Wi-Fi or microwave links, to establish wireless connections between network devices. Wireless backbones are typically 
    used in scenarios where running physical cables is impractical or cost-prohibitive, such as in remote or outdoor environments. Wireless backbones are less common than wired or fiber optic 
    backbones and are typically used in smaller networks or as supplemental connectivity options in conjunction with wired backbones.    
    Virtual Backbone: A virtual backbone, also known as a logical backbone or a virtual LAN (VLAN) backbone, is a logical or virtual grouping of network segments or VLANs that are interconnected 
    using network switches or routers. VLANs are created by dividing a physical network into smaller logical segments, allowing for network segmentation, improved security, and better network 
    management. VLAN backbones are commonly used in large networks where logical segmentation is desired without the need for physically separate backbone cabling.    
    Cloud-based Backbone: Cloud-based backbones utilize cloud-based networking services, such as virtual private networks (VPNs), software-defined wide area networks (SD-WANs), or cloud 
    interconnects, to establish a virtual network backbone over the Internet or other public or private cloud networks. Cloud-based backbones are ideal for distributed networks or organizations 
    that rely on cloud-based resources and services, providing flexible and scalable connectivity options without the need for physical backbone infrastructure.
    <img src="images/1.8.backbone.jpg" alt="" width="29%" height="40%">
Network Segment: A network segment, also known as a network segment or a LAN segment, refers to a smaller portion of a larger network that is separated by network devices, such as switches or 
routers. A network segment may consist of a group of devices, such as computers, servers, printers, and other networked devices, that are connected to the same local area network (LAN) or a 
virtual LAN (VLAN) and can communicate directly with each other without the need for intermediate routing or switching. Network segments are used to divide a large network into smaller manageable 
parts, improve network performance, and manage network traffic.
The purpose of a protocol is to establish a common understanding and agreement among participants in a communication or interaction process. Protocols define the format, structure, and sequence of 
data exchanged, as well as the rules for error detection, correction, and handling.
<b>OSI</b> stands for Open Systems Interconnection. It is a conceptual model that describes how network communication occurs between different computer systems or devices. The OSI model was developed 
by the International Organization for Standardization (ISO) in the 1980s as a reference framework for understanding and standardizing network communication protocols. The OSI model consists of seven 
layers, each representing a specific function or task in the network communication process. These layers are:
<img src="images/2.1.OSImodelexample.jpg" alt="" width="79%" height="40%">
Data encapsulation on network communication
<img src="images/2.2.dataencapsulation.jpg" alt="" width="39%" height="40%">
TCP header typically includes the following fields:
    Source Port: This field identifies the source application or process on the sending device.
    Destination Port: This field identifies the destination application or process on the receiving device.
    Sequence Number: This field contains a unique number that represents the position of the data segment within the stream of data being transmitted.
    Acknowledgment Number: This field contains the sequence number of the next expected data segment from the receiving device, acknowledging the receipt of previously received data.
    Data Offset: This field specifies the length of the TCP header in 32-bit words, indicating the start of the TCP payload (data) field.
    Reserved: This field is reserved for future use and is currently set to zero.
    Flags: This field contains control bits that specify various TCP options, such as SYN (synchronize), ACK, FIN (finish), RST (reset), and others, to control the behavior of the TCP connection.
    Window Size: This field indicates the size of the receive window, which specifies the amount of data that the receiving device is willing to accept without requiring further acknowledgment.
    Checksum: This field contains a calculated value based on the contents of the TCP header and data, used for error detection.
    Urgent Pointer: This field is used to indicate the presence of urgent data in the TCP payload, and points to the last byte of urgent data.
    Options: This field is used for carrying additional optional information, such as maximum segment size (MSS), selective acknowledgment (SACK), and others.
    Padding: This field is used to ensure that the TCP header is aligned on a 32-bit boundary, and is filled with zeroes if needed
IP (Internet Protocol) header typically includes the following fields:
    Version: This field indicates the version of the IP protocol being used, such as IPv4 or IPv6.    
    Header Length: This field specifies the length of the IP header in 32-bit words, indicating the start of the IP payload (data) field.    
    Type of Service (TOS): This field is used to specify the priority, quality of service (QoS), and other characteristics of the IP packet.    
    Total Length: This field indicates the total length of the IP packet, including the header and data, in bytes.    
    Identification: This field contains a unique value that is used to identify a particular IP packet, and is used in fragmentation and reassembly of large IP packets.    
    Flags: This field contains control bits that specify various options for handling fragmentation and reassembly of IP packets, such as "Don't Fragment" (DF) and "More Fragments" (MF).    
    Fragment Offset: This field indicates the position of the data fragment within the original IP packet, in case the IP packet has been fragmented into smaller pieces.    
    Time to Live (TTL): This field specifies the max number of hops (routers) that the IP packet is allowed to traverse before being discarded, to prevent from circulating indefinitely in the network.    
    Protocol: This field indicates the type of protocol used in the data payload of the IP packet, such as TCP, UDP, ICMP, or others.    
    Header Checksum: This field contains a calculated value based on the contents of the IP header, used for error detection.    
    Source IP Address: This field contains the IP address of the sender (source) of the IP packet.    
    Destination IP Address: This field contains the IP address of the intended recipient (destination) of the IP packet.    
    Options: This field is used for carrying additional optional information, such as route information, security options, and others.
LLC header typically includes the following fields:
    Destination Service Access Point (DSAP): This field identifies the upper layer (network layer or higher) protocol to determine the destination protocol entity at the receiving end.
    Source Service Access Point (SSAP): This field identifies the upper layer (network layer or higher) protocol to determine the source protocol entity at the sending end.    
    Control: This field contains control information that is used for managing the data link connection, such as flow control, error control, and connection establishment and termination.
Frame Check Sequence (FCS): This field contains a checksum or cyclic redundancy check (CRC) value that is used for error detection in the MAC header and data payload of the data packet.
MAC header typically includes the following fields:
    Destination MAC address: This field identifies the MAC address (also known as the hardware address or physical address) of the intended recipient device on the local network.  
    Source MAC address: This field identifies the MAC address of the sending device on the local network. It is used to indicate the source of the data packet.    
    Type or Length field: This field indicates the type of data being carried in the data packet, or the length of the data packet.    
PDU stands for "Protocol Data Unit." It refers to the unit of data that is transmitted at each layer of the OSI (Open Systems Interconnection) model or other networking protocol models. Each layer 
in the OSI model has its own PDU format, and these PDUs are used to encapsulate data as it is passed down or up the protocol stack.
In computer networking, the maximum transmission unit (MTU) refers to the maximum size of a data unit that can be transmitted over a particular network protocol at one time. In the case of Ethernet-
based networks, the MTU is typically set to 1500 bytes. When a 1500-byte packet is sent over an Ethernet-based network, it is encapsulated with an Ethernet header and trailer, which add additional 
bytes to the overall size of the packet. Once the packet is encapsulated with the Ethernet header and trailer, it can be transmitted over the network in a single shot as a single frame(12000 bits). The 
frame will be received by the destination host, which will then strip off the Ethernet header and trailer to access the original 1500-byte packet. If a host wants to send a packet that is larger than 
1500 bytes, it will be fragmented into multiple smaller packets that can be transmitted over the network.
Here's how the data from an HTML form with two fields (email and phone number) would be encapsulated as it passes through each layer of the OSI model:
    Application Layer: The user fills out the form on their web browser, which is an application layer protocol. The data for the email and phone number fields are sent to the web server using the 
    HTTP at the application layer. The HTTP protocol encapsulates the data in a header that includes information about the HTTP version, request method, and URI.
    Presentation Layer: The data is not manipulated at this layer, so no encapsulation is added.
    Session Layer: The data is not divided into smaller units at this layer, so no encapsulation is added.
    Transport Layer: The HTTP message is broken up into smaller segments(if it is larger than 1500 bytes) to be transmitted more efficiently over the network. The transport layer protocol, which 
    is likely the TCP, adds a header to each segment that includes a sequence number, acknowledgement number, and other control information. The TCP protocol also performs error checking on each 
    segment to ensure reliable delivery.
    Network Layer: The TCP segments are encapsulated in an IP packet. The IP protocol adds a header to the packet that includes the source and destination IP addresses, as well as other routing 
    information. The IP packet is then forwarded towards the destination using routing protocols.
    Data Link Layer: The IP packet is encapsulated in a frame by the data link layer protocol, which could be Ethernet. The frame header includes the source and destination MAC addresses, as well as 
    other data link layer information. The frame trailer includes error checking information.
    Physical Layer: The frame is converted into a physical signal that can be transmitted over the physical medium, such as a copper cable or wireless signal.
    <img src="images/2.3.messagepassingthroughmultiplelayers.jpg" alt="" width="39%" height="40%">  <img src="images/2.4.messagepassingthroughmultiplelayers.jpg" alt="" width="49%" height="40%">
Some mnemonics that can help you remember the order of the OSI layers:
    Please Do Not Throw Sausage Pizza Away
    All People Seem To Need Data Processing
Connection-oriented and connectionless communication are two different approaches to transmitting data in computer networks.
    Connection-oriented communication: In connection-oriented communication, a reliable and established connection is first established between the sender and receiver before data transfer occurs. This 
    connection is maintained throughout the entire data transfer process, and both the sender and receiver exchange control information to ensure that the data is received correctly. Examples of 
    connection-oriented protocols include TCP (Transmission Control Protocol), which is used in the TCP/IP protocol suite commonly used in the Internet, and the X.25 protocol.
    Connectionless communication: In connectionless communication, data packets are transmitted independently without establishing a dedicated connection between the sender and receiver. Each packet is 
    treated as an independent unit and can take different routes to reach the destination. The receiver does not send any acknowledgment or control information back to the sender, and the responsibility 
    for ensuring reliable delivery of data is typically handled by higher-level protocols or applications. Examples of connectionless protocols include UDP (User Datagram Protocol), which is also used 
    in the TCP/IP protocol suite, and the IP (Internet Protocol) itself.
There are several popular cables used for networking, including:
    Coaxial Cable: Coaxial cables are used for various networking applications, including cable TV, internet, and CCTV systems. They have a central conductor surrounded by an insulating layer, a 
    metal shield, and an outer insulating layer. Coaxial cables are capable of carrying high-frequency signals and are commonly used in environments where high-quality signal transmission is 
    important. Coaxial cable is primarily used by cable TV companies to connect their satellite antenna facilities to customer homes and businesses. For many networking applications, twisted pair 
    Ethernet cables, such as Cat 5e, Cat 6, Cat 6a, and Cat 7, have become more prevalent due to their higher bandwidth, faster data transfer speeds, and ease of installation. These cables are 
    commonly used in bus topologies
    <img src="images/3.1.coaxialcable.jpg" alt="" width="19%" height="40%">
    Twisted pair cable: Twisted pair cables are a type of cabling commonly used for networking and telecommunications. They consist of pairs of insulated copper wires that are twisted together in a 
    specific pattern to reduce interference and improve performance. The twisting of the wires helps to cancel out electromagnetic interference (EMI) and radio frequency interference (RFI) that can 
    occur during data transmission, allowing for more reliable and higher-quality signal transmission. Twisted pair cables are widely used to transmit data signals between devices such as computers, 
    routers, switches, and access points. These cables are commonly used in star topologies, ring topology and mesh topology. There are two main types of twisted pair cables:
        Shielded Twisted Pair (STP) cables: STP cables, also known as screened twisted pair (ScTP) cables, are similar to UTP cables, but they have an additional layer of shielding around the twisted 
        pairs. This shielding provides extra protection against electromagnetic interference (EMI) and radio frequency interference (RFI). STP cables are less common compared to UTP cables and are 
        typically used in specific networking environments that require higher levels of EMI and RFI protection, such as in industrial settings or in areas with high electromagnetic interference. 
        <img src="images/3.3.2.shieldedtwistedpaircables.jpg" alt="" width="9%" height="40%">
        The following are some Ethernet standards that may use STP cables:
        <img src="images/3.5.1.STPcableproperties.jpg" alt="" width="49%" height="40%">
        Unshielded Twisted Pair (UTP) cables: UTP cables are the most common type of twisted pair cables used in networking. They consist of pairs of insulated copper wires that are twisted together 
        without any additional shielding. UTP cables are used in various Ethernet cable categories, such as Cat 5e, Cat 6, Cat 6a, and Cat 7, and are typically color-coded for easy identification 
        and termination. 
        <img src="images/3.3.1.unshieldedtwistedpaircables.jpg" alt="" width="9%" height="40%">
        The following are some of the most common Ethernet standards that utilize UTP cables:
        <img src="images/3.5.2.UTPcableproperties.jpg" alt="" width="69%" height="40%">
        The T568A and T568B are two different wiring standards used for Ethernet cabling, specifically for terminating Ethernet cables with RJ45 connectors. These standards define the pin assignments 
        for the eight wires inside the Ethernet cable and determine how they should be connected to the pins of the RJ45 connector. Both standards differ in the arrangement of the wire pairs within 
        the connector. 
        T568A  standard uses the following pin assignments:
            Pair 1 (Pin 1 and 2 (White/Green and Green)): Transmit (TX) and Receive (RX) for Ethernet data
            Pair 2 (Pin 3 and 6 (White/Orange and Orange)): Transmit (TX) and Receive (RX) for Ethernet data
            Pair 3 (Pin 4 and 5 (Blue and White/Blue): Unused
            Pair 4 (Pin 7 ans 8 (White/Brown and Brown): Unused
        T568B:
            Pair 1 (Pin 1 and (White/Orange and Orange)): Transmit (TX) and Receive (RX) for Ethernet data
            Pair 2 (Pin 3 and (White/Green and Green)): Transmit (TX) and Receive (RX) for Ethernet data
            Pair 3 (Pin 4 and 5 (Blue and White/Blue)): Unused
            Pair 4 (Pin 7 and 8 (White/Brown and Brown)): Unused
        Two types of Ethernet cables that are used for different purposes in networking
            Straight-through cable: A straight-through cable, also known as a patch cable, is used to connect different types of network devices that have different functions, such as connecting a 
            computer to a switch or a router to a modem. In a straight-through cable, the pin assignments on one end of the cable are wired to the same standard (either T568A or T568B) as the pin 
            assignments on the other end of the cable.
            <img src="images/3.13.straight-throughethernetcable.jpg" alt="" width="19%" height="40%">
            Crossover cable: A crossover cable, also known as a crossover patch cable, is used to directly connect two similar network devices without the need for a switch or a router in between, 
            such as connecting two computers or two switches. In a crossover cable, the pin assignments on one end of the cable are wired to a different standard (T568A or T568B) than the pin 
            assignments on the other end of the cable, which allows for the proper exchange of data between the two devices.
            <img src="images/3.14.crossoverethernetcable.jpg" alt="" width="19%" height="40%">
        The naming conventions for STP and UTP cables in Ethernet standards typically follow similar patterns. Here's a general guide on how STP and UTP cables are typically named:
            Data Transfer Rate: The data transfer rate, which indicates the speed at which data can be transmitted over the network, is usually specified as a number in Mbps, Gbps, or higher.
            Cable Type: The cable type, whether it's STP or UTP, may be indicated in the naming convention. For example, "T" typically indicates UTP cables, while "F" or "X" may indicate fiber 
            optic cables, and "S" or "L" may indicate STP cables.
            Maximum Distance: The maximum distance that data can be transmitted over the network using the specified cable type is usually indicated in the naming convention. This distance is usually 
            expressed in meters or feet and indicates the maximum length of the cable that can be used for network connections.
            Other Parameters: Some standards may include additional parameters, such as the encoding scheme used for data transmission, the type of connectors used, or other specifications.
        "10GBASE-T" is an Ethernet standard that specifies 
            "10G" in the name indicates the data transfer rate of 10 Gbps
            "BASE" indicates that it uses baseband signaling, which means that the entire bandwidth of the cable is dedicated to carrying Ethernet data
            "T" indicates that twisted pair copper cables are used for network connections
        "Cat" stands for "Category" and refers to a classification system used for Ethernet cables that indicates the performance and capabilities of the cable. Different Cat versions correspond to 
        different standards set by the TIA/EIA for Ethernet cabling. Overview of the main differences between these Cat versions:
        <img src="images/3.6.catversions.jpg" alt="" width="69%" height="40%">
    Fiber Optic Cable: Fiber optic cables are used for high-speed and long-distance networking applications. They use light to transmit data, offering faster data transfer rates and better immunity to 
    interference compared to Ethernet cables. Fiber optic cables are commonly used in data centers, telecommunication networks, and other environments where high bandwidth and long-distance 
    transmission are required. These cables are commonly used in ring topologies and mesh topology. There are several different modes of fiber optic cables available, which refer to the way light 
    travels within the fiber core. 
    <img src="images/3.2.fibreopticcables.jpg" alt="" width="19%" height="40%">
    The most common modes of fiber optic cables are:
        Single-mode (SM): Single-mode fiber optic cables have a small core diameter (typically 9/125 µm or 8.3/125 µm) and allow for only one mode, a single path of light propagation , of light to 
        travel through the core. Single-mode fibers are designed for long-distance transmission and are used in high-bandwidth applications such as long-haul telecommunications, data centers, and 
        campus networks. Single-mode fiber is using laser as the source of the light for transmission of the optical signal and transmission media is glass.
        Multimode (MM): Multimode fiber optic cables have a larger core diameter (typically 50/125 µm or 62.5/125 µm) and allow for multiple modes, allows for multiple modes of light propagation, 
        of light to travel through the core. Multimode fibers are typically used for shorter distances, such as within buildings or campuses, and are suitable for lower-bandwidth applications such 
        as local area networks (LANs), premises cabling, and some data center applications. Multimode fiber is using LEDs as the source of the light for transmission of the optical signal and cables 
        are available in glass or in a plastic version. Single mode cables are meant for long distance, while multimode is often used for shorter distances
        <img src="images/3.9.singlevsmultimodecabledifference.jpg" alt="" width="29%" height="40%"> 
        Here is the main differences in characterization between single-mode and multimode fiber optic cables:
        <img src="images/3.8.singlevsmultimodedifference.jpg" alt="" width="89%" height="40%"> 
        Within multimode fibers, there are also different types of multimode fibers that are optimized for different performance characteristics: 
        <img src="images/3.7.variousmutimodetypes.jpg" alt="" width="49%" height="40%">
    There are several types of fiber optic connectors commonly used in the industry, including:
        SC (Subscriber Connector): SC connectors are one of the most widely used fiber optic connectors. They have a square-shaped push-pull mechanism for easy insertion and removal, and they provide 
        low insertion loss and high return loss.        
        LC (Lucent Connector): LC connectors are small form-factor connectors that use a 1.25 mm ferrule, making them half the size of SC connectors. They are commonly used in high-density applications 
        and provide low insertion loss and high return loss.        
        ST (Straight Tip): ST connectors are one of the older types of fiber optic connectors and are commonly used in older networks. They have a round, bayonet-style coupling mechanism and use 
        a 2.5 mm ferrule.        
        FC (Ferrule Connector): FC connectors use a threaded coupling mechanism and a 2.5 mm ferrule. They are commonly used in applications that require high precision and stability, such as in 
        laboratory settings.        
        MTP/MPO (Multi-Fiber Push-On/Pull-Off): MTP/MPO connectors are used for multi-fiber cables and provide high-density connectivity. They have a push-pull mechanism and can accommodate multiple 
        fibers in a single connector, making them ideal for data centers and high-speed networks.        
        MT-RJ (Mechanical Transfer Registered Jack): MT-RJ connectors are duplex connectors that combine a fiber optic connection with a copper RJ-style connector in a single housing. They are 
        commonly used in residential and small office/home office (SOHO) applications.
        E2000: E2000 connectors have a spring-loaded shutter that protects the fiber when not in use, making them ideal for applications that require dust and dirt protection. They provide low 
        insertion loss and high return loss.
        <img src="images/3.10.fiberopticconnectors.jpg" alt="" width="69%" height="40%">
Here's a comprehensive list of network topologies, along with the commonly used cables for each topology:
<img src="images/3.4.cabletypeandtopology.jpg" alt="" width="79%" height="40%">
A rollover cable is a type of networking cable that is commonly used to connect a computer or networking device, such as a router or switch, to the console port of another networking device. It is 
also known as a Cisco console cable or a serial console cable. The purpose of a rollover cable is to establish a console connection between networking devices for the purpose of configuration, 
management, and troubleshooting. By connecting a computer or terminal to the console port of a networking device using a rollover cable, network administrators can access the command-line 
interface (CLI) or the configuration mode of the device's operating system, allowing them to configure various settings, monitor the device's performance, and troubleshoot issues. A rollover cable 
typically has a 9-pin or 25-pin serial connector on one end (which connects to the console port of the networking device) and an RJ-45 Ethernet connector on the other end (which connects to the 
computer or terminal). The pinouts of the serial connector are wired in a "rollover" pattern, which means that the signals from the pins on one end of the cable are "rolled over" to different pins 
on the other end of the cable. This allows the console connection to function properly and allows for communication between the computer and the networking device. Rollover cables are often used 
in Cisco networking devices, but can also be used with other networking equipment that has a similar console port.
<img src="images/3.11.rollovercable.jpg" alt="" width="9%" height="40%"> <img src="images/3.15.rolledethernetcable.jpg" alt="" width="19%" height="40%">
Hardware loopback is a method used in computer networking and telecommunications to test the functionality of network interfaces, cables, and other networking hardware. It involves creating a 
loopback connection within the hardware itself, where data sent from a device is immediately received by the same device, without being transmitted over a network. In a hardware loopback setup, 
a loopback plug or loopback adapter is typically used to connect the transmit (TX) and receive (RX) lines of a network interface or cable, creating a loop that allows data to be sent and received 
locally. This allows for testing of the physical and data link layers of the OSI model, which include checking for proper signal transmission, link integrity, and other hardware-related 
issues. Hardware loopback can be used for various purposes, such as testing the functionality of 
    Network cards
    Diagnosing network connectivity issues
    Verifying the integrity of network cables. 
<img src="images/3.12.1.hardwareloopbackfiberoptic.jpg" alt="" width="9%" height="40%"> <img src="images/3.16.hardwareloopback.jpg" alt="" width="9%" height="40%">
Cabling refers to the process of installing and organizing cables in a network infrastructure to establish connections between devices or systems for data, voice, or video communication. Cables 
are physical pathways that carry electrical or optical signals from one device to another, allowing for the transfer of data or other types of information. Cabling is a critical component of any 
network, including LANs, WANs, data centers, and other communication systems. Proper cabling is essential for establishing reliable and efficient network connections, ensuring data integrity, 
minimizing signal loss or interference, and facilitating smooth communication between devices. Proper cabling techniques are important to minimize signal loss, interference, and other issues that 
can affect network performance and reliability. Cables are typically installed according to specific standards, guidelines, and best practices to ensure optimal performance and compliance with 
industry standards. Cabling may involve tasks such as 
    Cable routing
    Cable termination (i.e., connecting cables to connectors or devices)
    Cable testing
    Cable management (i.e., organizing and securing cables)
    Documentation (i.e., labeling and documenting cable connections for future reference and troubleshooting)
Several components are typically involved in cabling, depending on the specific type of cabling and network infrastructure. Some common components used in cabling include:
    Cables: There are various types of cables used in networking, such as 
        Ethernet cables (e.g., Cat 5e, Cat 6, Cat 6a)
        Fiber optic cables
        Coaxial cables
        Other types of copper or wireless cables
        <img src="images/3.22.ethernetCATfiberopticcoaxialcables.jpg" alt="" width="49%" height="40%">
    Connectors: Connectors are used to terminate the ends of cables and provide a physical connection between cables and devices. Examples of connectors commonly used in cabling include 
        RJ-45 connectors for Ethernet cables
        LC or SC connectors for fiber optic cables
        BNC connectors for coaxial cables
        <img src="images/3.18.RJ45LCSCBNCconnectors.jpg" alt="" width="49%" height="40%">
    Patch Panels: Patch panels are used to provide a centralized point for connecting and managing multiple cables. They typically have multiple ports where cables from various devices are terminated. Patch 
    panels typically do not come with keystones by default.
    <img src="images/3.25.patchpanel.jpg" alt="" width="19%" height="40%">
    Keystone Jacks: Keystone jacks are modular connectors that are used in wall plates, patch panels, and other network devices. They provide a connection point for cables to be terminated.
    <img src="images/3.26.keystonejacks.jpg" alt="" width="9%" height="40%">
    Patch Cords: Patch cords, also known as patch cables or patch leads, are short lengths of cables with connectors on both ends. 
    <img src="images/3.27.patchcords.jpg" alt="" width="29%" height="40%">
    Cabinets or Racks: Cabinets or racks are used to house and organize network equipment, including patch panels, switches, routers, and other devices. 
    <img src="images/3.28.cabinets.jpg" alt="" width="19%" height="40%">  
    Cable Management Accessories: Various accessories are used to organize and secure cables, ensuring a neat and organized cabling layout. Such as 
        Cable trays
        Cable ties
        Cable labels
        Cable clips
    <img src="images/3.29.cabletraysclipslablesties.jpg" alt="" width="49%" height="40%"> 
    Testing and Certification Equipment: Testing and certification equipment, such as cable testers and certifiers, are used to verify the performance and integrity of cables, ensuring that they 
    meet industry standards and are capable of transmitting data or other signals effectively.
    <img src="images/3.30.cabletesterscertifiers.jpg" alt="" width="29%" height="40%"> 
There are several methods for cabling, which refer to the different ways in which network cables are installed and organized to establish connectivity between devices in a network. Some of the common 
methods for cabling include:
    Structured Cabling: Structured cabling is a standardized approach to designing and installing a comprehensive cabling infrastructure system that can support various types of communication and 
    data transmission within a building or facility. It involves organizing and connecting cabling systems, such as Ethernet cables, fiber optic cables, and other types of copper and coaxial cables, 
    to create a reliable and flexible network infrastructure that can handle voice, data, video, and other types of signals. Structured cabling typically follows industry standards, such as the 
    TIA/EIA-568 and ISO/IEC 11801, and involves components such as patch panels, keystone jacks, and patch cords.
    <img src="images/3.31.structuredcabling.jpg" alt="" width="19%" height="40%">
    Point-to-Point Cabling: In this method, each device or system in a network is connected directly to another device or system using individual, dedicated cables. Point-to-point cabling is simple 
    and easy to set up, but it can result in a complex and tangled cabling layout, which can be difficult to manage and maintain, especially in larger networks.
    Home Run Cabling: also known as star topology, involves running individual cables from each device directly to a central point, such as a patch panel or switch. This method provides a centralized 
    and organized cabling layout, making it easier to manage and troubleshoot network connections.
    Daisy Chaining: also known as bus topology, involves connecting devices in a linear chain or daisy chain fashion, where each device is connected to the previous device in the chain using a single 
    cable. This method is simple and cost-effective, but it can be prone to network disruptions if one device or cable fails, affecting the entire chain.
    Wireless Cabling: also known as wireless networking, uses wireless technology, such as Wi-Fi, to establish network connectivity between devices without the need for physical cables. Wireless 
    cabling provides flexibility and mobility, but it may not be suitable for all types of devices or environments, and may have limitations in terms of speed, security, and range.
Structured cabling refers to a standardized and organized approach for designing, installing, and managing a comprehensive cabling infrastructure system within a building or facility. It is 
typically used to establish a reliable and scalable foundation for various information and communication technology (ICT) networks, such as local area networks (LANs), data centers, voice over 
IP (VoIP) networks, and other networked systems. Structured cabling systems typically consist of a hierarchical and modular arrangement of standardized cabling components, including horizontal 
cabling, backbone cabling, patch panels, connectors, outlets, and other hardware, along with associated pathways, conduits, and cable management systems. These components are designed to support 
the transmission of data, voice, and video signals, and provide a flexible and future-proof infrastructure that can accommodate current and future networking technologies. The key principles of 
structured cabling include:
    Standards-based approach: Structured cabling systems adhere to industry standards, such as the TIA/EIA-568-C series and ISO/IEC 11801, which define the requirements for various cabling components, 
    performance, and installation practices. Compliance with standards ensures interoperability, compatibility, and performance of the cabling infrastructure.
    Modularity and scalability: Structured cabling systems are designed to be modular and scalable, allowing for easy additions, modifications, and upgrades without disrupting the entire cabling 
    infrastructure. This provides flexibility and adaptability to changing networking requirements and technologies.
    Hierarchical architecture: Structured cabling systems typically have a hierarchical architecture, with a central distribution point (such as a main distribution area or MDA) connected to 
    intermediate distribution points (such as horizontal distribution areas or HDAs), which are in turn connected to end-user devices or equipment. This hierarchical structure simplifies management 
    and troubleshooting of the cabling infrastructure.
    Documentation and labeling: Structured cabling systems require thorough documentation and labeling of cabling components, including cables, patch panels, and outlets, to aid in installation, 
    troubleshooting, and maintenance activities.
    Cable management: Structured cabling systems incorporate cable management practices and systems, such as racks, cabinets, and pathways, to organize and protect cables, minimize interference, 
    and facilitate maintenance and upgrades.
Structured cabling typically requires several facilities and components to ensure efficient and reliable network connectivity within a building or campus. These may include:
    Telecommunications rooms (TRs) or data centers: These are dedicated rooms or spaces within a building or campus where the cabling infrastructure is terminated, managed, and distributed. TRs or 
    data centers are typically designed with proper environmental conditions, such as temperature, humidity, and security, to house networking equipment, patch panels, and other components of the 
    structured cabling system. These facilities may include:
        Main Distribution Frame (MDF): The MDF is the central distribution point for a structured cabling system, where the incoming backbone cabling from the service provider or external network is 
        terminated, and connections are made to the horizontal cabling for different areas or zones within a building or campus. The MDF typically houses the main networking equipment, such as 
        switches, routers, and servers, and may also include patch panels, cable management accessories, and power backup systems.    
        Intermediate Distribution Frame (IDF): IDFs are secondary distribution points that are strategically located throughout a building or campus to serve as intermediate connectivity points 
        between the MDF and the end devices in different areas or zones. IDFs typically house patch panels, switches, and other networking equipment, and are connected to the MDF via backbone cabling. 
        <img src="images/3.32.MDFIDF.jpg" alt="" width="29%" height="40%"> 
        Equipment Rooms: Equipment rooms are dedicated spaces within a building or campus where networking equipment, servers, and other critical IT infrastructure are housed. These rooms typically 
        have specialized environmental controls, such as cooling, power backup, and fire suppression systems, to ensure the reliable and secure operation of the equipment.    
        Data Centers: Data centers are specialized facilities designed to house mission-critical IT infrastructure, including servers, networking equipment, storage devices, and other hardware, for 
        data storage, processing, and management. Data centers are typically larger and more sophisticated than TRs and may have redundant power and cooling systems, backup generators, advanced 
        security measures, and other features to ensure high availability and uptime for critical IT operations.    
        Server Rooms: Server rooms are smaller spaces within a building or campus that are dedicated to housing servers and related networking equipment. They may be used in smaller facilities or 
        as additional spaces to support the IT infrastructure beyond the MDF, IDF, or data center, depending on the size and complexity of the network.    
        Telecommunications Closets: Telecommunications closets are small, localized spaces that house networking equipment, patch panels, and related infrastructure to serve a specific area or zone 
        within a building. These closets are typically used in smaller facilities or as additional connectivity points beyond the MDF and IDFs, and may have limited environmental controls compared to 
        larger TRs or data centers.   
    Backbone cabling: also known as vertical cabling, this refers to the cabling infrastructure that interconnects different TRs or data centers within a building or campus. It typically consists of 
    high-capacity cables, such as fiber optic or copper cables, that are used to establish connections between TRs or data centers to enable communication and data transfer between different areas 
    of the facility.    
    Horizontal cabling: This refers to the cabling infrastructure that connects the TRs or data centers to the end devices, such as workstations, telephones, cameras, and other networked devices, 
    within each area or zone of the building or campus. It typically consists of copper cables, such as Cat5e or Cat6, or fiber optic cables, that run from the TRs or data centers to the outlets 
    or jacks located in each area or zone.    
    <img src="images/3.33.backboneandhorizontalcabling.jpg" alt="" width="29%" height="40%"> 
    Patch panels: These are panels with jacks or connectors that are used to terminate and manage network connections in the TRs or data centers. Patch panels provide a central point for terminating 
    and organizing the horizontal cabling, backbone cabling, and active networking equipment, such as switches and routers.    
    Patch cords: These are short, pre-terminated cables with connectors on both ends that are used to establish connections between the patch panels, networking equipment, and end devices. Patch cords 
    are used to connect the jacks on the patch panels to the jacks or ports on active networking equipment or end devices, facilitating the establishment of network connections.    
    Networking equipment: This includes active networking devices, such as switches, routers, and other network devices, that are used to route, switch, and manage network traffic within the structured 
    cabling system. Networking equipment is typically installed in the TRs or data centers and connected to the patch panels and other components of the structured cabling system.    
    Cable management accessories: These include various accessories, such as cable trays, racks, cabinets, and labels, that are used to manage, organize, and protect the cabling infrastructure. Cable 
    management accessories help maintain a clean and organized cabling system, ease troubleshooting and maintenance, and ensure the overall reliability and performance of the structured cabling system.    
    Testing and certification tools: These include tools, testers, and certification equipment used to test, verify, and certify the performance and quality of the cabling system, ensuring that it meets 
    industry standards and performance requirements.    
    Documentation and labeling: Proper documentation and labeling are critical for a well-organized and maintainable structured cabling system. This may include documentation of cabling layouts, labeling 
    of patch panels, cables, and outlets, and other relevant information to aid in troubleshooting, maintenance, and future modifications.
Demarc, short for demarcation point, is the point of interface between the telecommunications service provider's network and the customer's premises in a telecommunications or data networking system. It 
marks the boundary between the service provider's responsibility for the external network and the customer's responsibility for the internal network.
A smart jack, also known as a managed service demarcation point or a managed service handoff, is a type of network interface device (NID) or demarcation point that provides advanced features and 
functionality for managing and monitoring telecommunications or data networking services at the customer's premises. A smart jack is typically used in situations where the customer receives managed 
services, such as high-speed Internet access, voice over IP (VoIP) services, or other data networking services from a service provider, and requires advanced capabilities for troubleshooting, monitoring, 
and managing the services at their premises.
<b id="id_ethernet_specifications_details">Ethernet Specifications</b>
Ethernet is a set of standards and protocols that specify the physical and data link layer aspects of networking, which are the first two layers of the OSI (Open Systems Interconnection) model. Ethernet 
was developed by Xerox Corporation in the 1970s and has since become the dominant LAN technology in use today. It is used to connect devices such as computers, servers, switches, routers, and other 
network-enabled devices in a LAN, allowing them to communicate and share data with each other. Ethernet uses a contention-based media access method, known as Carrier Sense Multiple Access with Collision 
Detection (CSMA/CD), where devices on the network compete for access to the network medium to transmit data. Ethernet frames, which are the data packets used in Ethernet networks, are encapsulated with 
source and destination MAC (Media Access Control) addresses, and they are transmitted over a physical network medium, such as copper cables or optical fibers, using various signaling methods and encoding 
schemes. Ethernet has evolved over the years to support different data rates, ranging from 10 Mbps (Ethernet) to 100 Gbps (Ethernet), and beyond. It has also been adapted for different physical media, 
such as twisted pair copper cables (e.g., Cat5e, Cat6, Cat6a), coaxial cables (e.g., 10BASE2, 10BASE5), and fiber optic cables (e.g., 1000BASE-SX, 10GBASE-LR). 
A collision domain is a term used in networking to define the network segment or portion of a LAN (Local Area Network) where network devices share the same network medium and can potentially collide with 
each other when attempting to transmit data simultaneously. When two or more devices transmit data at the same time, their data packets may collide, resulting in corrupted data. When a collision is 
detected, the devices stop transmitting and wait for a random time before attempting to retransmit the data again, which can cause delays and reduce network performance. A collision domain is typically 
limited to a single network segment or LAN segment, which is typically defined by a hub or a repeater in Ethernet networks. Hubs and repeaters are devices that operate at the Physical layer of the OSI 
model and simply regenerate and amplify network signals, extending the physical reach of the network but not providing any isolation or segmentation of collision domains. In contrast, devices such as 
switches or bridges operate at the Data Link layer of the OSI model and provide individual collision domains for each of their ports. Switches and bridges are capable of forwarding network traffic only 
to the destination port, effectively isolating collision domains and reducing the likelihood of collisions. This can improve network performance and reduce network congestion in larger LANs. In modern 
Ethernet networks, switches are commonly used, and the concept of collision domains is not as relevant as it was in the past when hubs and repeaters were more commonly used. Switches are capable of 
creating multiple collision domains, isolating network segments and improving network performance by reducing the likelihood of collisions.
CSMA/CD is an important mechanism used in Ethernet networks to regulate access to the network medium and prevent collisions from degrading network performance. However, it is worth noting that 
CSMA/CD is used in traditional Ethernet networks based on half-duplex communication, where devices can either transmit or receive data at a time, and collisions can occur. In modern Ethernet 
networks, full-duplex communication is commonly used, where devices can transmit and receive data simultaneously on separate channels, eliminating the need for CSMA/CD as collisions are 
rare. Here's how CSMA/CD works step-by-step:
    Carrier Sense: Before a device transmits data on the network, it listens for carrier signals on the network medium to check if it's free or busy. If the medium is found to be busy, the device 
    waits until it becomes idle before attempting to transmit.
    Multiple Access: Once the device detects that the network medium is idle, it starts to transmit its data. Multiple devices on the network may attempt to transmit data simultaneously, but only 
    one device can transmit successfully at a time due to the physical limitations of the network medium.
    Collision Detection: If two or more devices transmit data simultaneously and their signals collide on the network medium, a collision occurs. When a device detects a collision during its 
    transmission, it immediately stops transmitting and sends a jamming signal to inform other devices that a collision has occurred.
    Backoff and Retransmission: After a collision is detected, each colliding device waits for a random period of time before attempting to retransmit its data. This is called the "backoff" 
    period, and it helps to reduce the likelihood of another collision occurring immediately after the first collision. The backoff period is calculated based on the binary exponential backoff 
    algorithm, where each colliding device selects a random waiting time within a predefined range, and the range increases exponentially with each collision. Once the backoff period expires, 
    the device that initiated the backoff attempts to retransmit its data.
    Repeat the Process: The process of carrier sense, multiple access, collision detection, backoff, and retransmission continues as long as there are devices on the network that need to transmit data.
Half-duplex and full-duplex are two different modes of operation for Ethernet networks, which determine how data can be transmitted and received over the network.
    Half-Duplex Ethernet: In half-duplex Ethernet, data can be transmitted or received, but not both simultaneously. When a device is transmitting data, it cannot receive data at the same time, and 
    vice versa. Devices using half-duplex Ethernet must wait for the network to be clear before they can transmit data to avoid collisions, where two devices try to transmit data simultaneously, 
    resulting in data loss. Half-duplex Ethernet uses a shared medium, where all devices on the network share the same communication channel.    
    Full-Duplex Ethernet: In full-duplex Ethernet, data can be transmitted and received simultaneously, allowing for faster and more efficient communication. Devices using full-duplex Ethernet have 
    separate channels for transmitting and receiving data, eliminating the need for collision detection and avoiding data loss due to collisions. Full-duplex Ethernet can be used in point-to-point 
    connections or in networks with switches or hubs that support full-duplex operation.
    <img src="images/4.2.halfandfullduplex.jpg" alt="" width="19%" height="40%"> 
A broadcast domain is a term used in networking to define the network segment or portion of a LAN (Local Area Network) within which broadcast traffic is forwarded. Broadcast traffic is network traffic 
that is sent to all devices within a particular network segment, and it is typically used for tasks such as address resolution, network discovery, and network management. When a device broadcasts a 
frame, it is received by all devices within the broadcast domain, regardless of their MAC addresses. This can result in increased network traffic and potential network congestion, especially in larger 
LANs with many devices generating broadcast traffic. A broadcast domain is typically limited to a single LAN segment or network segment, which is defined by a switch or a router in Ethernet 
networks. Routers are used to interconnect multiple LAN segments or network segments, and they can also define broadcast domains. Routers typically do not forward broadcast traffic between different 
network segments, which helps to isolate broadcast domains and prevent broadcast storms, which can occur when broadcast traffic is forwarded in an uncontrolled manner and overwhelms the network.
In modern Ethernet networks, switches and routers are commonly used to create and manage broadcast domains, and the concept of broadcast domains is an important consideration in network design and 
configuration to optimize network performance, reduce network congestion, and improve network security.
<img src="images/4.1.broadcastdomain.jpg" alt="" width="29%" height="40%"> 
Ethernet is a set of standards that define the physical and data link layers of the OSI (Open Systems Interconnection) model. The physical layer defines the physical characteristics of the network 
medium, such as the electrical or optical properties of the cables, connectors, and signaling methods. The data link layer provides the means for transmitting data over the physical medium, including 
how data is framed, addressed, and transmitted between devices on the same network segment. Here are some commonly used Ethernet specifications:
<img src="images/4.3.ethernetwiredandwirelessspecifications.jpg" alt="" width="59%" height="40%"> 
Ethernet at data link layer, is responsible for 
    Ethernet addressing, commonly referred to as hardware addressing or MAC addressing. The MAC address is a unique identifier assigned to the network interface card (NIC) of a network device, such 
    as a network adapter in a computer, a switch, or a router. MAC addresses are typically 48 bits (6 bytes) in length, and they are represented in hexadecimal notation. A computer with multiple 
    physical NICs and virtual NICs may have multiple MAC addresses associated with it, corresponding to the number of NICs present in the system. A MAC address is divided into two parts:
        Organizationally Unique Identifier (OUI): The first 24 bits (3 bytes) of a MAC address are known as the OUI. The OUI is assigned by the Institute of Electrical and Electronics Engineers (IEEE) 
        and identifies the manufacturer or vendor of the network device, it is common to all NICs produced by that vendor.
        Device Identifier: The last 24 bits (3 bytes) of a MAC address, following the OUI, are known as the device identifier. The device identifier is assigned by the manufacturer and is unique to each 
        network interface card (NIC) produced by that manufacturer. The device identifier is used to uniquely identify a specific NIC among all the NICs produced by the same manufacturer.
    Ethernet frames, Ethernet framing is the process of encapsulating data into Ethernet frames for transmission over Ethernet networks. The Ethernet frame is the basic unit of data that is transmitted 
    and received over an Ethernet network. The process of Ethernet framing typically involves the following steps:
        Data Segmentation: The data to be transmitted is divided into smaller units called frames. Each frame typically consists of a header(14-byte), data payload(1500-byte), and a trailer(4-byte). 
        <img src="images/4.4.ethernetframe.jpg" alt="" width="59%" height="40%">    
        Transmitting the Frame: The completed Ethernet frame is then transmitted over the network using the appropriate physical layer, such as twisted pair cables, coaxial cables, or fiber optic cables.
Ethernet at physical link layer
    The process of converting an Ethernet frame to bits involves several steps, including encapsulation, encoding, modulation, and transmission.
        Encapsulation: data is encapsulated on ethernet frames on data link layer
        Encoding: The Ethernet frame is then encoded into a sequence of bits. Different encoding schemes are used depending on the specific Ethernet standard being used, such as Manchester encoding, 
        4B/5B encoding, or 8B/10B encoding. These encoding schemes are used to convert the binary data of the Ethernet frame into a format suitable for transmission over the network medium, which may 
        involve modulation of electrical or optical signals.
        Modulation: In some Ethernet standards, such as those that use twisted-pair copper cables, the encoded bits are further modulated onto the physical medium using a modulation technique, such as 
        pulse amplitude modulation (PAM), in which the amplitude or voltage of the signals is varied to represent different bits.
        Transmission: The modulated or encoded bits are then transmitted over the physical medium, such as the Ethernet cable, as a continuous stream of signals. The physical layer characteristics, 
        such as the signaling method, voltage levels, and timing, are defined by the specific Ethernet standard being used, and the receiving end of the transmission must adhere to the same standard 
        for proper decoding and processing of the transmitted bits.
    Various encoding schemas are
    <img src="images/4.6.variousencodingschemas.jpg" alt="" width="79%" height="40%">  
    A technical committee(802.3 Committee) within the Institute of Electrical and Electronics Engineers (IEEE) that is responsible for the development and maintenance of Ethernet standards. There 
    are several other committees within the IEEE that focus on different areas of networking and communication technologies. Some of the notable IEEE committees related to networking include: 
        802.11 Committee (Wireless LAN): This committee is responsible for the development of wireless local area network (WLAN) standards, commonly known as Wi-Fi, including the widely 
        used 802.11b, 802.11g, 802.11n, and 802.11ac standards.
        802.15 Committee (Wireless Personal Area Network): This committee focuses on the development of wireless personal area network (WPAN) standards, such as Bluetooth and Zigbee, which are 
        used for short-range wireless communication between devices in close proximity.
        802.16 Committee (Wireless Metropolitan Area Network): This committee is responsible for the development of wireless metropolitan area network (WMAN) standards, also known as WiMAX, 
        which provide broadband wireless access for metropolitan area networks.
        802.1 Committee (Bridging and Networking): This committee develops standards for bridging, interconnecting, and managing networks, including Ethernet bridging, virtual LAN (VLAN) tagging, 
        and network management protocols.
        802.3cg Committee (10 Mb/s Single Pair Ethernet): This committee focuses specifically for single-pair cabling, which is used in industrial and automotive applications.
    Some of the key IEEE 802.3 standards are:
        IEEE 802.3 Ethernet: This is the original Ethernet standard that defines the basic operation of Ethernet networks, including the physical layer (PHY) and the media access control (MAC) 
        layer. It includes specifications for various Ethernet data rates, such as 10 Mbps (10Base-T), 100 Mbps (100Base-TX), and 1000 Mbps (1000Base-T).            
        IEEE 802.3ae: This standard, also known as 10 Gigabit Ethernet, defines Ethernet operation at a data rate of 10 Gbps over optical fiber.            
        IEEE 802.3az: This standard, also known as Energy Efficient Ethernet (EEE), defines mechanisms for reducing power consumption in Ethernet networks during periods of low traffic.            
        IEEE 802.3ba: This standard, also known as 40 Gigabit Ethernet and 100 Gigabit Ethernet, defines Ethernet operation at data rates of 40 Gbps and 100 Gbps over various media, including optical 
        fiber and copper cables.            
        IEEE 802.3bt: This standard, also known as Power over Ethernet (PoE) Plus Plus, defines enhancements to PoE technology to deliver higher power levels for devices such as high-performance 
        wireless access points and pan-tilt-zoom (PTZ) cameras.            
        IEEE 802.3cg: This standard, also known as 10 Mb/s Single Pair Ethernet (SPE), defines Ethernet operation over a single twisted pair copper cable for industrial and automotive applications.            
        IEEE 802.3cu: This standard, also known as 100 Gigabit Ethernet over Backplane and Twinaxial Cables, defines Ethernet operation at a data rate of 100 Gbps over backplanes and twinaxial cables 
        commonly used in data centers.            
        IEEE 802.3cv: This standard, also known as Ethernet over Time-Sensitive Networking (TSN), defines Ethernet operation for real-time and time-sensitive applications, such as industrial 
        automation and automotive networks.            
        IEEE 802.3dd: This standard, also known as Precision Time Protocol (PTP) Transparent Clocks, defines mechanisms for accurate time synchronization in Ethernet networks for applications that 
        require precise timing, such as audio/video streaming and financial transactions.
<b id="id_networking_devices_details">Networking Devices</b>
Network devices refer to the hardware or software components that are used to establish, manage, and optimize computer networks. These devices enable communication and data exchange between different 
devices and users within a network. Network devices can be classified into several categories based on their functionality and purpose. Some common types of network devices include:
    Switches: Switches are used to connect devices within a local area network (LAN) and create a network by forwarding data packets between connected devices based on their MAC addresses. Switches 
    are typically used to provide multiple Ethernet ports for connecting devices such as computers, printers, and servers in a LAN.
    <img src="images/5.1.switches.jpg" alt="" width="19%" height="40%">     <img src="images/5.3.switchpurpose.jpg" alt="" width="29%" height="40%">   
        Routers: Routers are used to connect different networks together, such as connecting LANs to form a wide area network (WAN) or connecting a LAN to the Internet. Routers use routing tables and 
        protocols to determine the most efficient path for forwarding data packets between networks. Some of the primary functions of a router include:
        Packet forwarding: A router forwards data packets between different networks. It examines the header of each packet to determine its destination and chooses the best path to forward it to.      
        Network segmentation: Routers can be used to divide a large network into smaller subnets, enabling better network performance and security.
        Security: Routers can filter incoming and outgoing traffic based on various security policies to prevent unauthorized access and attacks.
        Quality of Service (QoS) management: It can prioritize certain types of traffic over others, ensuring that critical applications like voice and video are given priority over less important traffic.
        NAT (Network Address Translation): Routers can translate private IP addresses into public IP addresses, allowing devices on a private network to communicate with devices on the internet.
    VPN (Virtual Private Network) support: Routers can provide secure remote access to a private network by supporting VPN connections
    <img src="images/5.4.routers.jpg" alt="" width="19%" height="40%">     <img src="images/5.2.routerpurpose.jpg" alt="" width="29%" height="40%">   
    Hubs: Hubs are used to connect devices in a network, but they are less commonly used nowadays due to their limited functionality. Hubs simply broadcast incoming data packets to all connected 
    devices, which can cause collisions and network congestion.
    <img src="images/5.5.hub.jpg" alt="" width="19%" height="40%">     <img src="images/5.6.hubpurpose.jpg" alt="" width="29%" height="40%">  
    Modems: Modems are used to convert digital data into analog signals for transmission over telephone lines, cable lines, or other communication lines, and vice versa. Modems are commonly used for 
    connecting to the Internet or other remote networks.
    <img src="images/5.7.modem.jpg" alt="" width="19%" height="40%">     <img src="images/5.8.modempurpose.jpg" alt="" width="29%" height="40%">  
    Network Adapters: Network adapters, also known as network interface cards (NICs), are used to connect devices such as computers, servers, and printers to a network. Network adapters provide the 
    physical interface for connecting devices to the network and often support various Ethernet speeds (e.g., 10 Mbps, 100 Mbps, 1 Gbps, 10 Gbps) and types of network cables (e.g., Ethernet cables, 
    fiber optic cables).
    <img src="images/5.9.networkadapter.jpg" alt="" width="19%" height="40%"> 
    Repeaters/Extenders: Repeaters or extenders are used to amplify or regenerate signals over long distances in a network, allowing for longer cable runs and extending the reach of a network beyond 
    the limitations of the physical cabling.
    <img src="images/5.10.repeater.jpg" alt="" width="9%" height="40%">     <img src="images/5.11.repeaterpurpose.jpg" alt="" width="29%" height="40%">  
    Media Converters: Media converters are used to convert network signals between different types of media, such as converting Ethernet signals between copper cables and fiber optic cables. Media 
    converters are commonly used in network deployments where different types of cabling are used.
    <img src="images/5.12.mediaconverter.jpg" alt="" width="9%" height="40%">     <img src="images/5.13.mediaconveterpurpose.jpg" alt="" width="29%" height="40%">  
    Multilayer Switches(IP switch): A multilayer switch, also known as a Layer 3 switch, is a type of networking device that combines the functions of a traditional Layer 2 switch, which operates at 
    the data link layer (Layer 2) of the OSI model, and a router, which operates at the network layer (Layer 3) of the OSI model. This allows the multilayer switch to perform advanced routing and 
    switching functions, making it a versatile and powerful device for managing network traffic. Multilayer switches are used in data center and enterprise environments to provide advanced features 
    such as virtual LANs (VLANs), quality of service (QoS), and advanced security features. A basic network switch operates at Layer 2 (data link layer) of the OSI model and makes decisions based 
    on MAC addresses. It simply forwards data packets between devices connected to its ports based on their MAC addresses, without any awareness of IP addresses or higher-layer protocols. On the other 
    hand, a multilayer switch, as the name suggests, operates at multiple layers of the OSI model, including Layer 2 and Layer 3 (network layer). It can perform advanced routing and switching 
    functions based on both MAC and IP addresses, allowing it to make decisions based on IP subnets, perform inter-VLAN routing, and support more advanced networking protocols.
    <img src="images/5.14.multilayerswitches.jpg" alt="" width="9%" height="40%">     <img src="images/5.15.multilayerswitchespurpose.jpg" alt="" width="29%" height="40%"> 
    Wireless Access Points (WAPs): WAPs are used to provide wireless connectivity in a network, allowing devices such as laptops, smartphones, and tablets to connect to a network without using 
    physical cables. WAPs are commonly used in environments where wired connectivity is not feasible or where mobility is required.
    <img src="images/5.16.wap.jpg" alt="" width="9%" height="40%">     <img src="images/5.17.wappurpose.jpg" alt="" width="29%" height="40%">     
    Dynamic Host Configuration Protocol (DHCP) server: DHCP server is a network server that automatically assigns IP (Internet Protocol) addresses and other network configuration parameters to devices on a 
    TCP/IP (Transmission Control Protocol/Internet Protocol) network. The DHCP server manages a pool of IP addresses and leases them to devices, such as computers, smartphones, and other network 
    devices, on request.
    <img src="images/5.20.DHCPserverpurpose.jpg" alt="" width="29%" height="40%"> 
Apart from the common network connectivity devices mentioned earlier (such as switches, routers, hubs, bridges, and access points), there are also several specialized devices used in networking. These 
devices serve specific purposes and functions in modern networks. Some examples of specialized networking devices include:
    Firewall: A firewall is a network security device that monitors and filters incoming and outgoing network traffic based on an organization's previously established security policies. It acts as a 
    barrier between internal and external networks, helping to prevent unauthorized access and protecting the network from malicious activity.  
    <img src="images/5.18.firewall.jpg" alt="" width="19%" height="40%">     <img src="images/5.19.firewallpurpose.jpg" alt="" width="29%" height="40%">   
    Load Balancer: A load balancer is a device or software that distributes incoming network traffic across multiple servers or resources to ensure optimal utilization of resources and prevent overload 
    on a single server. Load balancers are commonly used in large-scale networks to distribute traffic across multiple servers, improving network performance and availability.  
    <img src="images/5.21.loadbalancer.jpg" alt="" width="19%" height="40%">     <img src="images/5.22.loadbalancerpurpose.jpg" alt="" width="19%" height="40%">   
    Proxy Server: A proxy server is an intermediary server that acts on behalf of clients to request resources from other servers. It can be used to provide various functions, such as caching commonly 
    accessed resources, filtering and controlling outbound and inbound network traffic, and enhancing security by adding an additional layer of protection between clients and servers.   
    <img src="images/5.23.proxyserver.jpg" alt="" width="19%" height="40%">     <img src="images/5.24.proxyserverpurpose.jpg" alt="" width="29%" height="40%">    
    Network Attached Storage (NAS): NAS is a specialized device that provides centralized storage accessible over a network. It allows multiple users or devices to store and access files from a central 
    location, providing data sharing and storage management capabilities for networks. 
    <img src="images/5.25.NAS.jpg" alt="" width="19%" height="40%">     <img src="images/5.26.NASpurpose.jpg" alt="" width="19%" height="40%">     
    VoIP Gateway: VoIP (Voice over Internet Protocol) gateway is a device that converts traditional analog voice signals into digital packets that can be transmitted over an IP network. It enables voice 
    communication over IP-based networks, such as the Internet, allowing for cost-effective voice communication over the same network infrastructure used for data communication.  
    <img src="images/5.27.VOIP.jpg" alt="" width="19%" height="40%">     <img src="images/5.28.VOIPpurpose.jpg" alt="" width="29%" height="40%">   
    Content Delivery Network (CDN): A CDN is a distributed network of servers that work together to deliver web content to users from a server that is geographically closer to them. CDNs are used to 
    accelerate content delivery, reduce latency, and improve performance of websites and web applications.  
    <img src="images/5.30.CDNpurpose.jpg" alt="" width="19%" height="40%">     
    Network Analyzer/Protocol Analyzer: Network analyzers or protocol analyzers are specialized devices or software tools used to capture, analyze, and diagnose network traffic. They provide insights 
    into network performance, troubleshoot network issues, and analyze network protocols for debugging and monitoring purposes.
    <img src="images/5.31.networkanalyzer.jpg" alt="" width="19%" height="40%">   
    Content Switch: A content switch is a specialized networking device that distributes incoming network traffic based on content or application layer information. It can inspect and analyze the 
    content of network packets, such as HTTP requests or XML data, to make intelligent routing decisions. Content switches are commonly used in large-scale networks to optimize content delivery, improve 
    performance, and ensure high availability of web-based applications or services.
    Intrusion Detection or Prevention System (IDS/IPS): An IDS/IPS is a security device or software that monitors network traffic for suspicious or malicious activity and alerts or prevents such 
    activity. IDS/IPS can detect and block known and unknown threats, such as malware, intrusions, and unauthorized access attempts. They are commonly used in networks to enhance network security 
    and protect against cyber threats.
    <img src="images/5.32.IDS.jpg" alt="" width="19%" height="40%">   <img src="images/5.33.IPS.jpg" alt="" width="19%" height="40%">  
    Bandwidth Shaper: A bandwidth shaper is a networking device or software that regulates and controls the amount of bandwidth allocated to different types of network traffic. It allows network 
    administrators to prioritize, limit, or shape the flow of network traffic based on predefined policies or rules. Bandwidth shapers are commonly used in networks to manage network congestion, 
    prioritize critical traffic, and optimize network performance.
    DNS Server: A DNS server is a specialized server that translates human-friendly domain names into IP addresses used by computers to identify each other on the Internet or a local network. DNS 
    servers are an essential part of the Internet infrastructure, and they are commonly used in networks to resolve domain names, manage domain records, and provide DNS-related services, such as 
    caching and authoritative DNS responses.
    <img src="images/5.34.DNSserverpurpose.jpg" alt="" width="19%" height="40%">
    Channel Service Unit/Data Service Unit (CSU/DSU): A CSU/DSU is a networking device that provides digital signaling and conversion between data terminal equipment (DTE) and data communication 
    equipment (DCE) in a digital communication link, typically over a T1 or E1 line. It is commonly used in wide area networks (WANs) to connect remote locations or branch offices to a central network.
    Storage Area Network(SAN): It is a specialized network that provides block-level access to data storage. The purpose of a SAN is to enable multiple servers to access a shared pool of storage devices, 
    such as disk arrays or tape libraries, without the need for direct connections between the servers and the storage devices. This shared storage can be used for a variety of purposes, including data 
    backup and recovery, high availability, and disaster recovery.
    Multifunction Network Devices: Multifunction network devices refer to networking devices that combine multiple functionalities into a single device. Examples include routers with built-in firewalls, 
    switches with integrated wireless access points, or all-in-one security appliances that combine firewall, VPN (Virtual Private Network), IDS/IPS, and other security functions. These devices are used 
    to simplify network architecture, reduce hardware costs, and streamline network management.
    Virtual private network (VPN) concentrators: A virtual private network (VPN) concentrator is a type of networking device that is used to create and manage secure connections between multiple 
    remote clients and a private network. The concentrator acts as a central point for VPN connections and manages the flow of traffic between the remote clients and the private network.
<b><a href="#id_network_segmentation_details" style="color: rgb(0, 0, 0); text-decoration: none;">Network Segmentation</a></b>
Network segmentation is the process of dividing a network into smaller subnetworks or segments to improve security and network performance. This separation is typically done for security, performance, 
or management reasons. A network segment can be a single subnet or a group of subnets that are connected by a common network device. A network segment can also refer to a logical division of a network, 
such as a virtual LAN (VLAN), which separates a network into multiple virtual networks. VLANs allow network administrators to group network devices together based on factors such as department or 
function, regardless of their physical location.
Routers and switches play important roles in network segmentation.
    Routers are networking devices that connect multiple networks and route traffic between them. They can be used to segment a network by creating separate network segments, or subnets, and 
    routing traffic between them. This can be done by assigning IP addresses to each subnet and configuring the router to direct traffic between them based on the IP address of the destination. By 
    controlling the flow of traffic between subnets, routers can help to enforce security policies and restrict access to sensitive resources.   
    Switches, on the other hand, are networking devices that connect multiple devices within a single network segment. They enable devices to communicate with each other by directing traffic to the 
    appropriate destination. Switches can be used to segment a network by creating multiple virtual local area networks (VLANs) within a single physical network infrastructure. VLANs enable network 
    administrators to group devices based on function, location, or security requirements, and to control traffic flow and access between them. By limiting traffic within VLANs, switches can help to 
    improve network performance and security by reducing congestion and isolating network traffic.
There are several common causes of LAN (Local Area Network) traffic congestion, including:
    Overutilization: When too many users or devices try to use the network at the same time, it can cause congestion.    
    Broadcast storms: When a broadcast message is sent to all devices on a network, it can cause a flood of traffic that overwhelms the network.    
    Network topology: The physical layout of a network can affect how efficiently data is transmitted. For example, a network with a lot of switches may have more congestion than one with fewer switches.    
    Network bandwidth limitations: The amount of bandwidth available on a network can limit the amount of data that can be transmitted at any given time. For example, if a network has a bandwidth 
    limitation of 100 Mbps, it means that the total amount of data that can be transmitted over the network during any given second cannot exceed 100 Mbps. If the total amount of data that needs to be 
    transmitted exceeds the available bandwidth, network congestion can occur, which can result in slow data transfer speeds, dropped connections, or other issues. 
    Faulty hardware or software: Malfunctioning or outdated network hardware or software can cause congestion by slowing down data transmission
Bridging in networking is the process of connecting two or more network segments together at the data link layer (Layer 2) of the OSI model. Bridging is typically used in LANs to expand their coverage 
area, increase the number of devices that can be connected to the network, and improve network performance by reducing congestion.
Collision domain is a network segment in which packet collisions can occur. A collision occurs when two or more devices on the same network segment try to transmit data at the same time, causing the 
signals to interfere with each other and resulting in data corruption or loss. Collision domains typically exist in shared media networks, such as Ethernet networks that use hubs 
to connect multiple devices. 
Broadcast domain is a network segment in which broadcast packets are forwarded to all devices on the segment. Broadcast packets are packets that are sent to all devices on the network, regardless of 
whether they are intended for a specific device or not. A broadcast domain is typically defined by a router or a switch configured with VLANs (Virtual Local Area Networks). By using VLANs, network 
administrators can separate the broadcast domains and limit the scope of broadcast traffic, reducing network congestion and improving network performance.
<img src="images/5.35.collisionbroadcastandmulticastdomains.jpg" alt="" width="59%" height="40%">  
A switch breaks the collision domain, which is the set of all devices on a network that can potentially collide with each other when transmitting data. Switches create a separate collision domain for 
each port, so that collisions are limited to the devices connected to that port. This allows for more efficient and reliable data transfer on the network.
A router breaks the broadcast domain, which is the set of all devices on a network that receive a broadcast message when it is sent out by any device on the network. Routers use a process called routing 
to selectively forward traffic between different networks based on their IP addresses. This limits the reach of broadcast messages and helps to prevent network congestion and unnecessary traffic.
<img src="images/5.36.calclatingcollisionandbroadcastdomain.jpg" alt="" width="69%" height="40%">  
There are two primary methods used in telecommunications to transfer data between devices: packet switching and circuit switching.
    Packet switching is a method where data is broken down into smaller units called packets, which are then sent individually over a network. Each packet contains the destination address, source 
    address, and other information necessary for delivery. Packets can take different paths to reach their destination and may arrive out of order, but they are reassembled in the correct order at 
    the destination device. An example implementation of packet switching is Voice over Internet Protocol (VoIP) calls. In VoIP, the voice signal is digitized and broken down into small packets, which 
    are then transmitted over the internet. Each packet is routed independently, and packets may take different routes to reach the recipient. At the recipient's end, the packets are reassembled 
    into the original voice signal. 
    Circuit switching is a method where a dedicated physical connection is established between two devices for the duration of a communication. In circuit switching, a connection is established 
    before any data transfer occurs. Once the connection is established, the devices communicate using a continuous stream of data until the connection is terminated. An example implementation of 
    circuit switching is the traditional telephone network. When a person makes a phone call, the telephone network establishes a dedicated physical connection between the caller and the recipient, 
    and a fixed amount of bandwidth is reserved for the duration of the call.
Here are the general steps that a router interface goes through to process and route network traffic:
    Data is received by the router interface from a device on the network, such as a computer or switch.    
    The router examines the header of the incoming packet to determine the destination IP address of the data.    
    The router looks up the destination IP address in its routing table to determine the best path to reach the destination network or device.    
    The router encapsulates the packet in a new frame appropriate for the outgoing interface, which may include changes to the source and destination MAC addresses.    
    The router forwards the packet to the next hop along the path to the destination, which may be another router or the final destination device.    
    The process repeats for each router along the path until the packet reaches its final destination.    
    If the router encounters any errors or problems during the routing process, it may discard the packet or send an error message back to the source device.    
    The router may also perform other functions on the data passing through its interfaces, such as filtering, shaping, or prioritizing traffic based on certain criteria.
Here are the general steps that a switch interface goes through to process network traffic:
    Data is received by the switch interface from a device on the network, such as a computer or another switch.    
    The switch examines the incoming frame to determine the destination MAC address of the data.    
    The switch checks its MAC address table to see if it has previously learned the MAC address.    
    If the MAC address is in the table, the switch forwards the frame out the appropriate interface to reach the destination device.    
    If the MAC address is not in the table, the switch floods the frame out all of its interfaces, except for the interface it received the frame on.    
    The destination device responds to the frame with its own frame containing its MAC address.    
    The switch learns the MAC address of the destination device and adds it to its MAC address table for future reference.    
    The switch forwards subsequent frames to the destination device out the appropriate interface.    
    If the switch encounters any errors or problems during the forwarding process, it may discard the frame or send an error message back to the source device.    
    The switch may also perform other functions on the data passing through its interfaces, such as filtering or prioritizing traffic based on certain criteria. 
All network connectivity relies on constantly updating ARP tables, MAC address tables, routing tables, and DNS tables. A network connectivity table contains addresses and interfaces associated with 
them. All of them are required to enable packet forwarding between subnets. Here are the steps for data traveling from source to destination
    DNS resolution: When a user wants to access a website or resource, their device sends a DNS query to a DNS server to resolve the domain name into an IP address.
    Routing table lookup: Once the IP address is obtained, the device consults its routing table to determine the best path to reach the destination network.
    ARP cache lookup: The device checks its ARP cache to see if it already has the MAC address of the next hop router or the destination device. If the MAC address is not in the cache, the device sends 
    an ARP request to obtain it.
    MAC address resolution: Once the device receives a response to the ARP request, it obtains the MAC address of the next hop router or destination device.
    Packet forwarding: The device forwards the packet to the next hop router or the destination device, using the MAC address obtained in the previous step.
    Repeat steps 2-5: The process repeats at each hop along the path until the packet reaches its destination network.
    Response packet: When the destination device receives the packet, it sends a response packet back to the source device, following the same steps as above.
There are several databases involved in the network data traveling, including:
    DNS database: The DNS database stores information about domain names and their corresponding IP addresses.  
    Routing table database: The routing table database stores information about the network topology and available routes to specific network destinations.    
    <img src="images/5.38.routingtable.jpg" alt="" width="19%" height="40%">  
    ARP cache database: The ARP cache database stores information about the MAC addresses of devices on the network.    
    <img src="images/5.37.ARPtable.jpg" alt="" width="19%" height="40%">  
    MAC address table database: The MAC address table database stores information about the MAC addresses of devices connected to a switch.    
    <img src="images/5.39.MACaddresstable.jpg" alt="" width="19%" height="40%">  
    Network address translation (NAT) table database: The NAT table database stores information about the translation between private IP used inside a network and public IP addresses used on the internet.
    <img src="images/5.40.NATtable.jpg" alt="" width="19%" height="40%">  
<b id="id_internet_protocol_details" style="color: rgb(0, 0, 0); text-decoration: none;">Internet Protocol (IP)</b>
History of TCP/IP, most of the development work on TCP/IP happened at UC Berkeley in Northern California, where a group of scientists were simultaneously working on the Berkeley version of UNIX, which soon 
became known as the BSD(Berkeley Software Distribution) series of UNIX versions. Because TCP/IP worked so well, it was packaged into subsequent releases of BSD UNIX and offered to other universities and 
institutions on a distribution tape. So basically, BSD UNIX bundled with TCP/IP began as shareware in the world of academia, and as a result, became the basis of the huge success and exponential growth of 
today’s Internet as well as smaller, private and corporate intranets.
TCP (Transmission Control Protocol) and IP (Internet Protocol) are used together because they provide complementary functions that are necessary for reliable and efficient communication over the Internet
and other networks. 
    IP is responsible for breaking up large chunks of data into smaller packets, adding the source and destination IP addresses to each packet, and routing them through the network to their final destination.
    TCP, on the other hand, provides reliable, ordered, and error-checked delivery of packets over the network. It establishes a connection between two devices and manages the flow of data between them 
    by breaking up the data into segments, numbering them, and reassembling them at the destination. TCP also provides mechanisms for error detection and recovery, ensuring that all data is delivered 
    correctly and in the correct order.
An IP network is a group of interconnected devices (such as computers, routers, switches, and servers) that use the IP to communicate with each other over a network. Different applications and services 
typically used in IP networks includes:
<img src="images/6.1.applicationsworksonTCPIPprotocol.jpg" alt="" width="79%" height="40%"> 
Telnet is a protocol that allows a user on one computer to establish a connection with another computer over the Internet or a local area network (LAN). The primary purpose of Telnet is to establish a 
remote terminal session with a Telnet server. A Telnet client connects to a Telnet server over a network using the Telnet protocol, which allows the client to access a command-line interface or 
application on the server as if it were running locally on the client's machine. To use Telnet, you need a Telnet client program installed on your computer and a Telnet server running on the remote 
computer that you want to connect to. Telnet is an unencrypted protocol, so all data (including login credentials) is sent in plain text. As such, it is generally recommended to use Telnet only on 
trusted networks and with caution. For secure remote access, consider using SSH or other encrypted protocols instead.
FTP (File Transfer Protocol) is a standard protocol used for transferring files between a client and a server over a network. The primary purpose of FTP is to enable users to download and upload 
files from and to a remote server. FTP works by establishing a connection between a client and a server using TCP/IP. The client sends requests to the server to download or upload files, and the 
server responds by sending the requested files or acknowledging the successful upload. FTP supports both binary and ASCII file transfer modes, and also allows users to navigate through directories 
on the remote server. To use FTP, you need a FTP client program installed on your computer and an FTP server running on the remote computer that you want to work with. However, it's worth noting 
that while FTP is still widely used, it has largely been replaced by more secure and efficient file transfer protocols such as SFTP (SSH File Transfer Protocol) and FTPS (FTP over SSL/TLS). These 
protocols offer encryption of data during transmission and stronger authentication mechanisms, which help to protect against eavesdropping and other security threats.
Network File System (NFS) is a distributed file system protocol that allows a user on a client computer to access files over a network as if those files were on the local computer. The purpose of NFS 
is to enable sharing of files and resources between computers, allowing multiple users to access the same files simultaneously. NFS works by having an NFS server export one or more directories 
to be shared, and NFS clients mount those directories on their local file system. Once mounted, the client can read and write files on the NFS server just as if they were local files. NFS is a widely 
used protocol in Unix and Linux environments, where it is used to share files between servers, workstations, and other devices. Server Message Block (SMB) protocol, which is used primarily in 
Microsoft Windows environments. SMB enables file sharing between computers running Windows or other operating systems, and supports features such as file and printer sharing, remote procedure 
calls (RPC), and authentication and authorization mechanisms. Another alternative is the Network Block Device (NBD) protocol, which allows remote storage devices to be mounted as local block 
devices on a client computer.
Simple Mail Transfer Protocol (SMTP) is a protocol used for sending email messages between servers and clients over a network. SMTP is responsible for transferring messages from one mail server 
to another, and for delivering messages to the recipient's mailbox. It works by establishing a connection between the client and server, and then exchanging commands and responses to initiate 
the email transmission process. To configure SMTP, you will typically need to set up an email server that supports SMTP, such as Microsoft Exchange, Postfix, or Sendmail. This server will need 
to be configured with the necessary settings, such as the domain name, email addresses, and authentication mechanisms. As for the latest alternative to SMTP, there are several new protocols 
and technologies that have emerged in recent years. One example is the Extensible Messaging and Presence Protocol (XMPP), which is used primarily for instant messaging and presence information 
but also supports email communication. Another example is the Simple Mail Transfer Protocol over TLS (SMTPS), which is an extension of SMTP that uses the Transport Layer Security (TLS) protocol 
for encryption and authentication. Finally, there is the newer messaging protocol, called the Message Queuing Telemetry Transport (MQTT) protocol, which is used for Internet of Things (IoT) 
applications, but can also be used for email messaging. Here are the steps involved in how SMTP works:
    The sender creates an email using an email client or webmail interface and clicks on the send button.
    The email client connects to the SMTP server of the sender's email provider using the SMTP protocol.
    The sender's SMTP server then checks the recipient's email domain name to determine the recipient's SMTP server.
    The sender's SMTP server establishes a TCP (Transmission Control Protocol) connection with the recipient's SMTP server on port 25.
    The sender's SMTP server sends the recipient's SMTP server the email message along with the sender and recipient email addresses.
    The recipient's SMTP server receives the email and performs a series of checks, such as checking if the recipient's email address is valid and if the message size is within acceptable limits.
    If the recipient's SMTP server determines that the email is acceptable, it stores the email in the recipient's mailbox on the server.
    The recipient's email client then retrieves the email from the recipient's SMTP server using protocols such as POP3 or IMAP.
    The recipient reads and responds to the email as desired.
Post Office Protocol (POP) is an email protocol used for retrieving email messages from a mail server. Its main purpose is to enable users to access their emails from remote locations without 
requiring a continuous connection to the email server. POP operates by downloading copies of emails from the mail server to a user's device or email client. Once the emails are downloaded, they 
are removed from the server, making them inaccessible to other devices or email clients. The latest alternative to POP is the Internet Message Access Protocol (IMAP). 
Internet Message Access Protocol (IMAP), The latest version of IMAP is version 4rev1, which is commonly referred to as IMAP4. IMAP4 is an email protocol used for retrieving and managing email 
messages from a mail server. Its purpose is to allow users to access their email from multiple devices and email clients while keeping the email messages stored on the server. The latest alternative 
to IMAP is the Exchange ActiveSync (EAS) protocol, which is primarily used for syncing emails, contacts, and calendars between mobile devices and email servers. However, IMAP is still widely used and 
is the preferred protocol for many email clients.
Transport Layer Security (TLS) is a cryptographic protocol used to secure communication over the internet. Its purpose is to provide confidentiality and integrity for data transmitted between two 
endpoints, such as a client and a server. TLS operates by establishing a secure connection between two endpoints, typically a client and a server, using a combination of symmetric and asymmetric 
encryption algorithms. This secure connection is established through a process called the TLS Handshake. TLS works on a client-server architecture. In a typical TLS connection, the client initiates 
a connection to the server and requests a secure connection. The server then responds and establishes a secure connection between the client and server using the TLS protocol. During the TLS Handshake 
process, the client and server exchange messages to agree upon the encryption algorithms, exchange keys, and verify each other's identity. Once the TLS Handshake is completed successfully, a secure 
connection is established between the client and server, and they can exchange encrypted data over the network.After the TLS Handshake is completed, the client and server can exchange encrypted data 
using the shared secret session key. The TLS Handshake involves the following steps:
    Client Hello: The client sends a Client Hello message to the server, indicating its support for TLS and its preferred TLS version, cipher suites, and other parameters.
    Server Hello: The server responds with a Server Hello message, indicating the TLS version, cipher suite, and other parameters that it has selected for the connection.
    Certificate: The server sends its SSL/TLS certificate, which contains its public key and other information necessary for the client to verify its identity.
    Server Key Exchange (optional): If the selected cipher suite requires it, the server sends additional information, such as a Diffie-Hellman public key, for use in generating the shared secret.
    Certificate Request (optional): If the server requires the client to authenticate itself, it sends a Certificate Request message, requesting the client's SSL/TLS certificate.
    Server Hello Done: The server sends a Server Hello Done message, indicating that it has completed its part of the Handshake.
    Client Key Exchange: The client generates a random session key and encrypts it with the server's public key obtained from the server's SSL/TLS certificate. The client then sends the encrypted 
    session key to the server.
    Certificate Verification (optional): If the server requested the client's SSL/TLS certificate, the client sends its certificate to the server for verification.
    Change Cipher Spec: The client and server agree to switch to the new session key and encryption algorithm by sending Change Cipher Spec messages.
    Finished: The client and server exchange Finished messages, which contain a hash of all the previous Handshake messages, encrypted with the newly established session key. This verifies that 
    both the client and server have the same session key and that the Handshake was successful.
<img src="images/6.2.TLShandshake.jpg" alt="" width="29%" height="40%">    
Here are the steps involved in how TLS works:
    The client initiates a connection request to the server and requests a secure connection.
    The server responds with its SSL/TLS certificate, which contains its public key.
    The client verifies the server's SSL/TLS certificate and checks its validity and trustworthiness.
    The client generates a random session key and encrypts it with the server's public key.
    The client sends the encrypted session key to the server, which decrypts it using its private key.
    The client and server now share a secret session key that can be used to encrypt and decrypt data exchanged between them.
    The client and server exchange encrypted data using the session key, ensuring that the data is kept confidential and cannot be tampered with by third parties.
HTTPS is simply HTTP over TLS, meaning that HTTP traffic is encrypted and decrypted using TLS encryption. When a client connects to an HTTPS-enabled website, the server responds with its SSL/TLS 
certificate, and a TLS Handshake occurs to establish a secure connection between the client and server. Once the TLS Handshake is completed successfully, the client and server can exchange encrypted 
data over the HTTPS connection. The latest alternative to TLS is the QUIC (Quick UDP Internet Connections) protocol. QUIC is a transport layer protocol developed by Google that is designed to provide 
low-latency and secure communication over the internet. It combines the features of TCP, TLS, and HTTP/2 into a single protocol, providing faster and more reliable communication than traditional protocols.
SIP (Session Initiation Protocol) is a protocol used in Voice over IP (VoIP) communications to set up, modify, and terminate voice or video calls between two or more endpoints over an IP network. SIP is 
an application-layer protocol that operates independently of the underlying transport layer and can run over both UDP and TCP. The purpose of SIP is to establish, modify and terminate multimedia sessions 
between two or more endpoints over the internet or private IP networks. SIP allows for the setup of various communication sessions, such as voice calls, video calls, and instant messaging, among 
others. SIP configuration involves the following steps:
    Choose a SIP provider: Select a SIP provider that can offer the required service for your business or personal use.
    Create a SIP account: Sign up for a SIP account with the chosen provider.
    Configure SIP settings: Configure the SIP client application with the SIP account credentials, including the SIP server hostname, port, username, and password.
    Test the SIP connection: Verify the SIP connection by making a test call to a SIP phone or another SIP-enabled device.
The latest alternative to SIP is WebRTC (Web Real-Time Communication), which is a newer protocol used for real-time communication between web browsers and other devices. WebRTC operates over the web 
and does not require any additional software or plugins to be installed on the device.
RTP (Real-time Transport Protocol) is a transport protocol used in VoIP (Voice over IP) communications to transport audio and video data over IP networks. The purpose of RTP is to transport audio and 
video data in a timely and efficient manner, ensuring that the audio and video packets arrive in the correct order and without delay, providing a smooth audio and video experience for 
users. Configuring RTP involves the following steps:
    Choose an RTP-capable VoIP system: Select a VoIP system that supports RTP, such as Asterisk, Cisco CallManager, or Microsoft Lync.
    Configure RTP settings: Configure the RTP settings in the VoIP system, such as the RTP port range, codec selection, packetization interval, and jitter buffer size.
    Test RTP functionality: Verify the RTP functionality by making a test call and monitoring the audio and video quality.
The latest alternative to RTP is SRTP (Secure Real-time Transport Protocol), which is a more secure version of RTP that provides encryption and authentication of the audio and video data.
Line Printer Daemon (LPD) is a protocol used for printing on a network printer. It enables a client computer to send print jobs to a printer connected to a print server or directly to a printer 
over the network. The purpose of LPD is to provide a standard method for sending print jobs between different computer platforms and operating systems. It allows multiple clients to share a 
single printer and enables remote printing, where users can print documents from their computer to a printer located in a different room or even in a different building. Configuring LPD involves 
the following steps:
    Enable LPD service: Enable the LPD service on the print server or printer that will be accepting print jobs over the network.
    Configure the printer: Configure the printer settings, such as print quality, paper size, and printer sharing, using the printer manufacturer's software.
    Configure the LPD server: Configure the LPD server settings, such as the listening port and printer name, using the LPD server software.
    Test the LPD service: Test the LPD service by sending a print job from a client computer to the printer and verifying that it prints correctly.
The latest alternative to LPD is the Internet Printing Protocol (IPP), which is a more advanced printing protocol that supports more features and provides better security and reliability.
X Window System, or X11, is a flexible and versatile windowing system that provides a graphical user interface (GUI) for Unix-based operating systems. Some of the main purposes of X11 include:
    Platform-independent GUI: X11 provides a standardized framework for creating and managing GUI, allowing developers to create applications that will run on a wide variety of Unix-based systems.
    Multi-user environment: X11 was designed to allow multiple users to work on the same machine or access a remote machine simultaneously.
    Remote access: X11 allows users to run graphical applications on a remote server and display them on a local machine, enabling remote access to applications and desktops.
Simple Network Management Protocol (SNMP) is an application-layer protocol used for managing and monitoring network devices such as routers, switches, and servers. Its purpose is to enable network 
administrators to manage, monitor and control network devices in a standardized way. SNMP allows network devices to be monitored and controlled remotely by a network management system (NMS). The NMS 
can request information from a network device using SNMP, such as the status of interfaces, the amount of traffic on a particular interface, and the amount of available disk space on a server. The 
NMS can also send control commands to network devices, such as shutting down an interface or restarting a service. The name of the latest alternative to SNMP is NETCONF (Network Configuration 
Protocol). NETCONF is a network management protocol that provides a mechanism to install, manipulate, and delete the configuration of network devices. It is designed to be more flexible, secure, 
and efficient than SNMP, which has been around for many years. NETCONF is a standardized protocol that is used by many vendors in the networking industry. It uses XML-based data encoding and provides 
features such as transactional operations, error reporting, and device notifications. NETCONF works by establishing a secure connection between a network management system (NMS) and a network device, 
typically a router or switch. Here are the basic steps involved in a NETCONF session:
    Connection Establishment: The NMS initiates a secure connection to the network device using the NETCONF protocol. This connection can use either the Secure Shell (SSH) or Transport Layer 
    Security (TLS) protocol for encryption and authentication.
    Capability Exchange: The NMS and the network device exchange information about their capabilities, such as which data models and operations they support.
    Data Model Selection: The NMS selects the data model it wants to use to configure the network device. A data model is a description of the configuration and operational state of the network 
    device, typically defined using the YANG language.
    Configuration Operation: The NMS sends a configuration operation request to the network device, such as adding a new interface or changing a routing policy. The device responds with the result 
    of the operation.
    Event Notification: The network device can send event notifications to the NMS to inform it of changes in the device's operational state, such as interface up/down events or error conditions.
    Session Termination: The NMS can close the NETCONF session when it has completed its tasks.
Secure Shell (SSH) is a cryptographic network protocol that provides a secure way to access remote systems over an unsecured network. Its purpose is to provide secure remote access and file 
transfer capabilities. The latest alternative to SSH is called Mosh (Mobile Shell), which is designed to provide a better user experience on high-latency networks, such as those encountered when 
using a mobile device. Unlike SSH, which is designed for low-latency networks, Mosh is designed to work on high-latency networks, such as those encountered when using a mobile device. Here are the 
steps to configure and use SSH:    
    Install SSH: You need to install an SSH server on the remote system you want to access, and an SSH client on the local system you want to connect from. Most Linux distributions include an SSH 
    server and client by default.    
    Configure SSH: You need to configure the SSH server on the remote system to allow remote access. This involves setting up a user account and setting appropriate permissions for files and directories.  
    Generate SSH Key: On the local system, you need to generate an SSH key pair. This consists of a public key and a private key. The public key is added to the remote system's authorized_keys file, which 
    allows you to log in without a password.    
    Connect using SSH: To connect to the remote system, you use the ssh command on the local system. This command takes the username and IP address or hostname of the remote system, as well as the path 
    to the private key file.    
    Secure File Transfer: SSH also provides a secure way to transfer files between systems using the scp (secure copy) command. This command allows you to copy files between systems using the SSH protocol.
Hypertext Transfer Protocol (HTTP) is an application protocol that is used for transmitting data over the internet. It is the foundation of data communication on the World Wide Web (WWW). The purpose of 
HTTP is to allow communication between web clients (such as web browsers) and web servers. When you type a URL into your web browser, the browser sends an HTTP request to the server, asking for the 
content associated with that URL. The server then sends back an HTTP response, which includes the requested content (such as an HTML page, an image, or a video). The latest alternative to HTTP 
is HTTP/2. This new version of the protocol was developed to improve the performance of web applications, particularly for mobile devices and high-latency networks. HTTP uses a text-based protocol, 
which means that the request and response messages are formatted as plain text. The messages include headers, which provide information about the message, and a body, which contains the content of 
the message. HTTP requests and responses are identified by a status code. Status codes indicate whether the request was successful, and if not, what the problem was. Common status codes include 
200 (OK), 404 (Not Found), and 500 (Internal Server Error). HTTP is stateless, which means that each request and response is independent of all others. This means that the server does not keep track 
of the state of the client, and each request must contain all of the necessary information for the server to process it. To allow for stateful interactions, web applications use cookies and other 
techniques to store information on the client side. Here are the steps to configure and use HTTP:
    Set up a web server: To use HTTP, you need to have a web server set up. Popular web servers include Apache, Nginx, and Microsoft IIS.
    Create web content: You need to create the content that you want to serve over HTTP. This can include HTML pages, images, videos, and other types of files.
    Configure the web server: You need to configure the web server to serve the content that you have created. This involves setting up virtual hosts, configuring file paths, and setting permissions.
    Access the content: To access the content, you use a web browser. The browser sends an HTTP request to the server, asking for the content associated with a particular URL.
    Receive the content: The server sends back an HTTP response, which includes the requested content. The response also includes metadata, such as the content type, status code, and caching information.
Hypertext Transfer Protocol Secure (HTTPS) is a secure version of the Hypertext Transfer Protocol (HTTP) that is used to transfer data securely between a client (such as a web browser) and a 
server (such as a web server) over the internet. The purpose of HTTPS is to provide a secure connection between the client and the server, ensuring that the data exchanged between them is encrypted 
and cannot be intercepted or tampered with by a third party. HTTPS is commonly used for secure online transactions such as e-commerce, online banking, and sensitive data transfer. The latest alternative 
for HTTPS is HTTP/3, which is based on the QUIC protocol. To configure HTTPS, a website owner needs to obtain an SSL/TLS certificate from a trusted certificate authority and install it on the web 
server. This certificate contains information such as the website owner's identity, the certificate's validity period, and a public key used to encrypt data. When a user requests a HTTPS webpage, the 
web server responds with its SSL/TLS certificate. The client verifies the certificate's authenticity and uses the public key to establish a secure connection with the server. The client and server then 
negotiate an encryption algorithm to use for the session and exchange encrypted data. This process ensures that any data exchanged between the client and server is secure and cannot be 
intercepted by a third party.
Network Time Protocol (NTP) is a protocol used to synchronize the time of a computer or networked device with a reference time source, such as a time server or atomic clock. The purpose of NTP is to 
ensure that all devices on a network are operating with the same time, which is critical for accurate logging, authentication, and other time-sensitive functions. The latest alternative for NTP 
is Precision Time Protocol (PTP), which offers even greater accuracy and precision than NTP. To configure NTP, a user needs to identify a time server to use as a reference source. This can be done 
by using the NTP Pool project, which provides a global network of time servers that are available for public use. Once a time server is identified, the user needs to configure their device or network 
to synchronize its clock with the server. This can typically be done through the device's settings or network configuration. When a device synchronizes with an NTP server, it exchanges time information 
with the server and adjusts its clock accordingly. NTP uses a hierarchical system of time servers, with each server in the hierarchy providing increasingly accurate and precise time information. This 
ensures that even devices that are located far from a reference time source can still maintain accurate time synchronization. Overall, NTP is an essential protocol for ensuring accurate time 
synchronization on computer networks, and is widely used in a variety of applications and industries. To configure the Windows Time service on a Windows machine by using the Windows Command Prompt or 
the Group Policy Editor. Some of the configuration options that can be set include the time source to use, the polling interval, and the maximum time correction value.To find the NTP server nearest 
to you using the NTP Pool Project, follow these steps:
    Visit the NTP Pool Project website at https://www.ntppool.org/.
    Select your region from the map or choose from the list of regions.
    The website will provide a list of NTP servers in your region, along with their IP addresses and other details.
    Choose an NTP server from the list and configure your system to use it for time synchronization.
Secure Copy Protocol (SCP) is a network protocol that allows secure file transfer between a local host and a remote host. SCP is based on the Secure Shell (SSH) protocol and uses the same authentication 
and encryption mechanisms to ensure secure data transfer. The purpose of SCP is to provide a secure and reliable way to transfer files between hosts on a network, while protecting the confidentiality 
and integrity of the data being transferred. The latest alternative to SCP is the File Transfer Protocol Secure (FTPS) and the SSH File Transfer Protocol (SFTP), both of which provide similar 
functionality for secure file transfer. To configure and use SCP, follow these steps:
        Install an SCP client on your local host, such as OpenSSH or WinSCP.
        Install an SSH server on the remote host, if it is not already installed. Most Linux and Unix-based systems come with an SSH server pre-installed.
        Configure the SSH server on the remote host to allow SCP file transfers. This typically involves adding or modifying configuration options in the SSH server's configuration file, such 
        as /etc/ssh/sshd_config on Linux and Unix-based systems.
        Open the SCP client on your local host and specify the source and destination paths for the file transfer, as well as the login credentials for the remote host.
        Initiate the file transfer and monitor the progress of the transfer.
        Once the file transfer is complete, verify the integrity of the transferred file by comparing its checksum with the checksum of the original file.
Lightweight Directory Access Protocol (LDAP) is an application protocol used to access and manage directory information. LDAP provides a standardized method for storing and accessing information 
about users, groups, and other resources in a network directory. The purpose of LDAP is to centralize and simplify the management of network resources by providing a single directory service that 
can be used by different applications and systems. LDAP also supports authentication and authorization, allowing network administrators to control access to resources based on user and group 
membership. The latest alternative to LDAP is the System for Cross-domain Identity Management (SCIM), which provides a standardized method for managing user identities across different systems 
and applications. To configure and use LDAP, follow these steps:
        Install an LDAP server on a network host, such as OpenLDAP or Microsoft Active Directory.
        Configure the LDAP server to store the directory information for your network, such as user accounts, groups, and permissions.
        Install an LDAP client on each system or application that needs to access the directory information. Most operating systems and applications provide built-in LDAP client support.
        Configure the LDAP client to connect to the LDAP server, specifying the server address and login credentials if required.
        Use the LDAP client to search, retrieve, and modify directory information as needed. This typically involves constructing LDAP queries to search for specific directory entries and using 
        LDAP APIs to interact with the directory server.
Internet Group Management Protocol (IGMP) is a communication protocol used by IP hosts and adjacent multicast routers to establish multicast group memberships. The purpose of IGMP is to allow 
hosts to inform multicast routers that they want to receive multicast traffic for a specific multicast group. This allows routers to forward multicast traffic only to those interfaces that have 
active members for that group, reducing network congestion and optimizing network performance. The latest alternative to IGMP is Multicast Listener Discovery (MLD), which is used in IPv6 networks
Line Printer Remote (LPR) is a protocol used to send print jobs from a client computer to a printer on a remote server over a network. It was developed by the Internet Engineering Task Force (IETF) 
as a standard for printing on a network. The purpose of LPR is to provide a simple and reliable way to print documents on a remote printer. It allows users to submit print jobs from their local 
machine and have them sent over the network to a printer on a remote server. This can be useful in situations where multiple users need to share a printer or where a printer is located in a different 
physical location from the client machine. The latest alternative for LPR is the Internet Printing Protocol (IPP), which provides additional features such as job status updates and printer discovery.
Domain Name Service (DNS) is a network protocol used for resolving domain names to IP addresses. It is used to translate human-readable domain names, such as www.example.com, into 
machine-readable IP addresses, such as 192.0.2.1. The purpose of DNS is to make it easier for users to access websites and other online resources without having to remember the IP addresses of the 
servers hosting those resources. DNS allows users to type in easy-to-remember domain names, which are then translated into IP addresses by DNS servers. There is currently no latest alternative for DNS 
as it remains the primary system for resolving domain names. To configure DNS, you would typically need to specify the IP address of one or more DNS servers in the network settings of your 
device. You can either use the DNS server provided by your internet service provider (ISP), or you can use a third-party DNS service such as Google DNS or OpenDNS.
Dynamic Host Configuration Protocol (DHCP) is a network protocol used to dynamically assign IP addresses and other network configuration parameters to devices on a network. Their purpose is to 
simplify network administration by automating the process of assigning IP addresses and reducing the risk of conflicts that can occur when addresses are assigned manually. The latest alternative 
to DHCP is known as IPv6 Stateless Address Autoconfiguration, which uses network prefixes and device MAC addresses to automatically assign unique IPv6 addresses to devices. To configure DHCP, you 
need a DHCP server and clients that support DHCP. The basic steps for configuring DHCP are as follows:
    Install and configure a DHCP server on the network.
    Configure the DHCP server with the appropriate settings, such as IP address range, lease time, and DNS server information.
    Connect the clients to the network and configure them to obtain their network settings automatically from the DHCP server.
    When a client connects to the network, it sends a broadcast message requesting an IP address.
    The DHCP server receives the broadcast and responds with an offer of an IP address and other network settings.
    The client accepts the offer and the DHCP server assigns the IP address to the client for the specified lease time.
    The client then uses the assigned IP address and network settings to communicate on the network.
<img src="images/6.3.DHCPnegotiation.jpg" alt="" width="19%" height="40%"> 
Automatic Private IP Addressing (APIPA), with APIPA, clients can automatically self-configure an IP address and subnet mask, which is the minimum information needed for hosts to communicate 
when a DHCP server isn’t available. The IP address range for APIPA is 169.254.0.1 through 169.254.255.254. The client also configures itself with a default class B subnet mask of 255.255.0.0.
Host-to-Host Layer Protocols refer to the set of protocols in the TCP/IP networking model that are responsible for ensuring reliable communication between two hosts or devices in a network. These 
protocols operate at the Transport layer of the TCP/IP model and are primarily concerned with end-to-end communication between applications running on different hosts. The two main protocols are 
    Transmission Control Protocol (TCP), TCP is a connection-oriented protocol that provides reliable and ordered delivery of data between two hosts
    User Datagram Protocol (UDP), UDP is a connectionless protocol that provides unreliable delivery of data
    Stream Control Transmission Protocol (SCTP),  SCTP is a transport layer protocol that provides reliable, ordered, and error-checked delivery of messages between applications. It is intended 
    to support applications that require higher levels of reliability and fault tolerance than can be provided by TCP or UDP. SCTP is becoming increasingly popular for use in applications such 
    as Voice over IP (VoIP) and teleconferencing.
    Datagram Congestion Control Protocol (DCCP), DCCP is designed to be flexible and extensible, allowing for the development of new congestion control mechanisms and congestion control algorithms 
    tailored to specific application requirements. Its main goal is to provide a reliable, congestion-controlled, and low-latency transport protocol for datagram-oriented applications, while avoiding 
    the overhead and complexity of traditional transport protocols like TCP. DCCP is primarily used in multimedia and streaming applications, such as VoIP, online gaming, and video conferencing, 
    where the timely delivery of data is critical and some loss of data is acceptable.
    Reliable Data Protocol (RDP), RDP is an open standard protocol that provides reliable delivery of data across IP networks. Its purpose is to enable reliable communication for real-time applications, 
    such as audio and video streaming, that require low latency and minimal loss or delay of data.
Transmission Control Protocol (TCP) takes large blocks of information from an application and breaks them into segments. It numbers and sequences each segment so that the destination’s TCP process can 
put the segments back into the order the application intended. After these segments are sent, TCP (on the transmitting host) waits for an acknowledgment from the receiving end’s TCP process, retransmitting 
those segments that aren’t acknowledged. Remember that in reliable transport operation, a device that wants to transmit sets up a connection-oriented communication with a remote device by creating a 
session. The transmitting device first establishes a connection-oriented session with its peer system, which is called a call setup or a three-way handshake. Data is then transferred; and when the transfer
is complete, a call termination takes place to tear down the virtual circuit. TCP is a full-duplex, connection-oriented, reliable, and accurate protocol. TCP segments a data stream and prepares it for the
Internet layer. When the Internet layer receives the data stream, it routes the segments as packets through an internetwork. The segments are handed to the receiving host’s Host-to-Host layer protocol, 
which rebuilds the data stream to hand to the upper-layer protocols. 
How TCP starts and close session, 
A series of steps known as the "three-way handshake" will establish for a connection and start exchanging data packets 
    SYN (Synchronize): The process begins with the sender (client) sending a SYN packet to the receiver (server) to initiate a connection request. The SYN packet contains information such as 
    the source and destination IP addresses, port numbers, and a randomly generated sequence number.
    SYN-ACK (Synchronize-Acknowledge): If the receiver (server) is willing to establish a connection, it responds with a SYN-ACK packet. The SYN-ACK packet acknowledges the receipt of the 
    SYN packet, contains its own randomly generated sequence number, and indicates the readiness to establish a connection.
    ACK (Acknowledge): Finally, the sender (client) sends an ACK packet to acknowledge the receipt of the SYN-ACK packet. This completes the three-way handshake process, and a connection 
    is established between the sender and receiver. The ACK packet typically contains the next sequence number that the sender is expecting to receive.
To terminate a connection, the steps are:
    FIN (Finish): The initiating party sends a FIN packet to the other party to signal that it wants to terminate the connection.        
    FIN-ACK (Finish-Acknowledge): The receiving party responds with a FIN-ACK packet to acknowledge receipt of the FIN packet.        
    ACK (Acknowledge): The initiating party then sends an ACK packet to confirm that it received the FIN-ACK packet. The receiving party also sends an ACK packet to confirm that it received 
    the ACK packet. Once both parties have sent and received ACK packets, the connection is considered terminated.
<img src="images/6.4.TCPcommunication.jpg" alt="" width="29%" height="40%">        <img src="images/6.5.TCPsegmenthead.jpg" alt="" width="29%" height="40%">  
The TCP header is 20 bytes long, or up to 24 bytes with options.
UDP (User Datagram Protocol) is a transport layer protocol used for sending and receiving datagrams over an IP network. Here are the steps involved in the start and end of a UDP process:
Start of UDP process:    
    Application sends data: The UDP process begins when an application sends data using the UDP protocol. The application specifies the source and destination IP addresses and port numbers, and 
    the data to be sent.    
    UDP encapsulates data: The UDP protocol encapsulates the application data into a UDP datagram, which includes a UDP header and the data.    
    IP encapsulates UDP datagram: The IP protocol encapsulates the UDP datagram into an IP packet, which includes an IP header and the UDP datagram.    
    IP packet sent to network: The IP packet is then sent to the network for transmission.    
End of UDP process:    
    UDP packet received: When the UDP packet arrives at its destination, the UDP protocol extracts the UDP header and the data from the packet.    
    Data passed to application: The UDP protocol then passes the data to the receiving application, which processes the data.
<img src="images/6.6.UDPdatagramhead.jpg" alt="" width="39%" height="40%"> 
TCP is a connection-oriented protocol, which means that it establishes a connection between two devices before sending data(creates a virtual circuit). TCP is commonly used for applications that require 
reliable and error-free transmission of data. UDP is a connectionless protocol, which means that it does not establish a connection before sending data(doesn't creates a virtual circuit). UDP is commonly 
used for applications that require fast and efficient transmission of data
<img src="images/6.7.TCPorUDPexamples.jpg" alt="" width="59%" height="40%"> 
TCP and UDP are two of the most commonly used transport layer protocols in computer networks. Some of their key features are:
<img src="images/6.8.keyfeaturesofTCPandUDP.jpg" alt="" width="29%" height="40%"> 
The overhead of a protocol refers to the additional data that is required for communication and is not part of the actual payload. TCP has a higher overhead compared to UDP because it provides reliable, 
ordered, and error-checked delivery of data, which requires additional data exchange for managing connections, error detection, and recovery. 
Windowing flow control is a mechanism used in the TCP to manage the flow of data between two devices communicating over a network. The basic idea is to limit the amount of data that can be transmitted 
at any given time based on the receiver's ability to handle it. The receiver advertises a "window size" to the sender, which indicates the amount of data it can receive and buffer at a given time. The 
sender then sends data up to the maximum allowed by the receiver's window size and waits for an acknowledgement before sending more data.
Port is a communication endpoint that is used to identify a specific process to which network data is to be sent or from which network data is to be received. Ports are identified by a number 
ranging from 0 to 65535. Ports are an essential part of networking, as they enable multiple processes to use the same network interface without interfering with each other. Port binding is the process 
of associating a specific network service or application with a particular port number on a host. When a network service or application starts, it binds to a particular port number to listen for incoming 
requests from other hosts on the network. This ensures that the service/application receives incoming network traffic on the designated port number and can process the requests accordingly. For example, a 
web server typically binds to port 80 or 443 (for HTTPS) to receive HTTP or HTTPS requests from web browsers. Similarly, an SSH server binds to port 22 to listen for incoming SSH connections. When 
incoming traffic arrives at a server, the network stack consults the system's routing table to determine which network interface the traffic should be delivered to. The network stack then checks the 
destination port number of the incoming traffic, and forwards it to the application or service that has bound to that port. A system's routing table, also known as a routing information base (RIB), is 
a database maintained by the operating system that stores information about the paths and metrics to reach different networks and hosts on a network. It contains a list of all the known networks and 
the next hop gateway or interface through which the traffic should be sent to reach those networks. The routing table is used by the operating system to determine the best path for forwarding traffic 
to its destination. When a packet is sent, the operating system looks up the destination IP address in the routing table and selects the best route based on the available paths, their associated 
costs, and other factors. The selected route is then used to forward the packet to the next hop towards its final destination. The RIB (Routing Information Base) is stored in the RAM (Random Access 
Memory) of a router or a network device. It is a data structure that holds the network topology information and the routing protocols updates received from different interfaces and protocols, such as 
OSPF, BGP, or RIP. The RIB is used to calculate the best path or route to reach a destination network or IP address, and the forwarding table (FIB) is populated with this information to perform 
packet forwarding. The use of different ports allows a computer to distinguish between different types of network traffic and direct it to the appropriate process. There are three types of ports:
    Well-known ports: These are reserved ports that are used by system processes or by programs executed by privileged users. They range from 0 to 1023 and are assigned by the Internet Assigned 
    Numbers Authority (IANA). The list of registered well-known ports can be obtained from the<a href="https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml" target="_blank" rel="noopener noreferrer">Internet Assigned Numbers Authority(IANA)</a> website. This list is regularly updated as new ports 
    are registered or deprecated. Some common examples of well-known ports are Port 80: HTTP (Hypertext Transfer Protocol), Port 443: HTTPS (Hypertext Transfer Protocol Secure), Port 25: SMTP (Simple Mail 
    Transfer Protocol), Port 110: POP3 (Post Office Protocol version 3), Port 143: IMAP (Internet Message Access Protocol), Port 22: SSH (Secure Shell). If the service or application uses a well-known 
    port, it requires administrative privileges or approval. It depends on the network configuration and security policies in place. 
    Registered ports: These are ports from 1024 to 49151 and are used by services or applications. It is common to configure access to registered ports to require administrative privileges
    Dynamic or private ports: These are ports from 49152 to 65535 used by the operating system for temporary connections and are not reserved for any specific service or application.
Internet Control Message Protocol (ICMP) is a protocol used by network devices, such as routers and hosts, to communicate error messages and operational information about network conditions. Its purpose 
is to report errors, provide diagnostic information, and aid in troubleshooting network issues. To configure ICMP, you typically do not need to take any specific steps, as it is already built into the IP 
stack of most operating systems. However, you can configure certain aspects of ICMP, such as enabling or disabling the ping command, using operating system-specific commands or utilities. ICMP works by 
embedding messages in IP packets, which are then transmitted across a network. When a router or host encounters an error or needs to transmit information, it will include an ICMP message in an IP packet 
and send it to the intended recipient. The recipient can then use the information contained in the ICMP message to diagnose and correct network issues. ICMP has several message types, including:
    Echo Request (Type 8) - used in ping requests to test network connectivity
    Echo Reply (Type 0) - used in ping responses to indicate successful connectivity
    Destination Unreachable (Type 3) - used to indicate that a packet cannot be delivered to its intended destination
    Time Exceeded (Type 11) - used to indicate that a packet has exceeded its allowed time to live (TTL) and has been discarded
    Redirect (Type 5) - used to inform a host that a better next-hop address for a particular destination exists
    Router Advertisement (Type 9) - used by routers to advertise their presence and to provide configuration information to hosts on a network
    Router Solicitation (Type 10) - used by hosts to solicit router advertisements on a network
Address Resolution Protocol (ARP) is a protocol used for mapping a network address (such as an IP address) to a physical address (such as a MAC address). Its main purpose is to allow communication 
between devices on a local network segment. When a device wants to send data to another device on the same network segment, it needs to know the MAC address of the destination device. The ARP protocol 
is used to query the network to find out the MAC address of the device with the specific IP address. Once the MAC address is known, the device can use it to send data to the correct destination. A newer 
protocols such as NDP (Neighbor Discovery Protocol) have been developed for IPv6 networks, which perform a similar function. Here are the basic steps involved in the ARP process:    
    The source device checks its ARP cache to see if it already has the MAC address of the destination device.
    If the MAC address is not found in the ARP cache, the source device sends a broadcast ARP request message to all devices on the local network segment asking for the MAC address associated with the 
    IP address of the destination device.
    The device with the matching IP address responds to the ARP request message with its MAC address.
    The source device updates its ARP cache with the MAC address of the destination device.
ARP cache database: The ARP cache database stores information about the MAC addresses of devices on the network.    
    <img src="images/5.37.ARPtable.jpg" alt="" width="29%" height="40%"> 
Proxy Address Resolution Protocol (Proxy ARP) is a protocol used in computer networking to allow devices to indirectly communicate with each other when they are on different IP subnets. Its purpose is 
to enable a device to act as a proxy for other devices on a network by responding to ARP requests on behalf of those devices. The latest alternative for Proxy ARP is the use of Layer 3 switches or 
routers with inter-VLAN routing capabilities. Proxy ARP isn’t really a separate protocol. It’s a service run by routers on behalf of other devices. Here are the steps on how Proxy ARP works:    
    A device on a network (Host A) wants to communicate with another device (Host B) on a different network.    
    Host A sends an ARP request for the MAC address of Host B's IP address.    
    The ARP request is broadcast on the local network.    
    The router on the local network receives the ARP request and checks its routing table to determine if it knows the location of Host B.    
    If the router does not know the location of Host B, it broadcasts a Proxy ARP request to all devices on the network.    
    The Proxy ARP request is broadcast to all devices on the network and is received by Host B.    
    Host B sends a reply to the router, which then forwards the reply to Host A.    
    Host A now knows the MAC address of Host B and can communicate with it.
Assuming that the 50 MB file is being transferred using TCP/IP protocol from host X to Host Y and 3 intermediate routers
    <img src="images/2.2.dataencapsulation.jpg" alt="" width="29%" height="40%">   <img src="images/6.9.PDUandlayeraddressing.jpg" alt="" width="29%" height="40%"> 
PDU stands for Protocol Data Unit. It is a term used in networking and communication to refer to the unit of data that is transmitted between two network entities at a particular layer of the 
protocol stack. Each layer of the protocol stack has its own PDU format and structure. The PDU at each layer contains the data, control information, and headers required by that layer. The PDU 
is then passed down to the next lower layer, which adds its own headers and control information, until it is transmitted over the network. At the receiving end, each layer removes its own headers 
and control information and passes the remaining data up to the next higher layer.
    The Layer 1 (Physical Layer) PDU is the bit
    The Layer 2 (Data Link Layer) PDU is the frame
    The Layer 3 (Network Layer) PDU is the packet
    The Layer 4 (Transport Layer) PDU is the segment for TCP or the datagram for UDP
    The Layer 5-6-7 (Application Layer) PDU is the data, which can be clear text, encrypted, or compressed
When transferring a 50 MB file using TCP/IP protocol from Host X to Host Y via 3 intermediate routers, the process can be broken down into several steps:
    File Segmentation: The file is segmented into smaller chunks or packets by the transport layer protocol, TCP. The packet size is determined by the Maximum Transmission Unit (MTU) of the 
    network. Let's assume a packet size of 1500 bytes.
    Encapsulation: Each packet(20,000) is encapsulated with a TCP header, which includes the source and destination port numbers, sequence and acknowledgment numbers, and other control information. Then 
    the packet is encapsulated with an IP header, which includes the source and destination IP addresses and other routing information.    
    Routing: The packet is then forwarded from Host X to Router A, then to Router B, then to Router C, and finally to Host Y. Each router inspects the destination IP address in the IP header and 
    uses its routing table to determine the next hop to forward the packet.    
    Decapsulation: At each intermediate router and at the receiving end, the packet is decapsulated by removing the IP and TCP headers to obtain the original data packet.    
    Reassembly: At the receiving end, the TCP protocol reassembles the packets into the original 50 MB file based on the sequence numbers in the TCP header.    
    Verification: The receiving end sends an acknowledgment back to the sending end for each packet received to verify that all packets have been successfully transmitted.
<b id="id_ip_addressing_details" style="color: rgb(0, 0, 0); text-decoration: none;">IP addressing</b>
An IP address (Internet Protocol address) is a unique numerical label assigned to every device connected to the internet. It serves as an identifier for the device and enables it to communicate 
with other devices on the internet. An IP address consists of four numbers separated by periods, for example, 192.168.0.1. Each number can range from 0 to 255, making the total number of possible 
IP addresses approximately 4.3 billion for IPv4. Each number in an IP address is also referred to as an "octet" because it represents 8 bits of the 32-bit IPv4 address. There are two types of IP 
addresses: IPv4 and IPv6. 
    IPv4 is a 32-bit address and is the most commonly used version of IP addresses
    IPv6 is a 128-bit address designed to replace IPv4 due to its limited number of available addresses
IP address: An IP address is a unique numerical identifier assigned to a device on a network. It consists of four numbers separated by periods, such as 192.168.0.1. IP addresses enable devices to 
send and receive data packets over a network.
Subnet mask: A subnet mask is a number that defines the range of IP addresses that are available within a particular network. It is used to separate the network portion of an IP address from the 
host portion. For example, in a network with a subnet mask of 255.255.255.0, the first three numbers in the IP address represent the network, and the last number represents the host.
Default gateway: The default gateway is the IP address of the device that enables devices on a network to communicate with devices on other networks. It acts as the entry and exit point for data 
packets between the local network and other networks, such as the internet. The default gateway is typically set to the IP address of the router on the local network.
Network address: A network address is the first IP address in a given network range, which is used to identify the network itself. This address is obtained by setting all the host bits to zero in 
the subnet mask. For example, if the IP address of a device on a network is 192.168.1.5, and the subnet mask is 255.255.255.0, then the network address is 192.168.1.0. The purpose of a network address 
is to identify a network on a larger network infrastructure, such as the Internet or a corporate network. A network address is a unique identifier that is used to route data between different networks, 
allowing devices on one network to communicate with devices on another network. For example, if a device on the network with IP address 192.168.0.10 wants to communicate with a device on a different 
network with IP address 10.0.0.5, the packet it sends will include both the source IP address (192.168.0.10) and the destination IP address (10.0.0.5), as well as the network address (10.0.0.0) of the 
target network. The network address is used by routers and other networking equipment to direct the packet to the correct network.
Broadcast address: A broadcast address is the last IP address in a given network range, which is used to send data packets to all devices on the network. This address is obtained by setting all the 
host bits to one in the subnet mask. For example, if the IP address of a device on a network is 192.168.1.5, and the subnet mask is 255.255.255.0, then the broadcast address is 192.168.1.255.
There are three common methods of representing IP addresses:
    Dotted Decimal Notation: This is the most commonly used method of representing IP addresses. It consists of four decimal numbers, each ranging from 0 to 255, separated by dots. For 
    example, 192.168.1.1 /24 is an IP address in dotted decimal notation with details like:
        CIDR notation: /24
        Subnet mask: 255.255.255.0
        Network bits: 24
        Host bits: 8
        Maximum number of IP addresses: 256
        Maximum number of usable host addresses: 254 (excluding network and broadcast addresses)
    Binary Notation: IP addresses can also be represented in binary notation, which is a base-2 numbering system using only two digits: 0 and 1. Each of the four octets of the IP address 
    is represented by eight binary digits (bits). For example, the IP address 192.168.1.1 in binary notation is 11000000.10101000.00000001.00000001.
    Hexadecimal Notation: Another way to represent IP addresses is in hexadecimal notation, which is a base-16 numbering system that uses 16 digits: 0 to 9 and A to F. Each octet of the 
IP address is represented by two hexadecimal digits. For example, the IP address 192.168.1.1 in hexadecimal notation is C0.A8.01.01.
The number of IP addresses that can be assigned to a device on a network is 254 when the IP address of that device is 192.168.1.5 and the subnet mask is 255.255.255.0, which is the number of IP 
addresses available on this network less the network address (192.168.1.0) and the broadcast address (192.168.1.255).
Hierarchical IP Addressing Scheme is a way of organizing IP addresses in a hierarchical structure based on their network prefixes. It is also commonly referred to as Classful addressing 
or Class-based addressing. In this scheme, IP addresses are divided into classes based on their first octet, which identifies the network address. The hierarchical IP addressing scheme defines 
three main classes of IP addresses: Class A, Class B, and Class C. However, the use of classful IP addressing has largely been replaced by classless addressing with the introduction of 
CIDR (Classless Inter-Domain Routing). Each class has a different range of network addresses and host addresses, as shown below:
    Class A addresses are used for large networks and have an 8-bit network portion and a 24-bit host portion. The first bit of a Class A address is always 0, and the range of Class A addresses is 
    from <b>1.0.0.0 to 126.0.0.0</b>, and it can support up to 126 different networks, each with up to 16,777,214 hosts.
    Class B addresses are used for medium-sized networks and have a 16-bit network portion and a 16-bit host portion. The first two bits of a Class B address are always 10, and the range of Class B 
    addresses is from <b>128.0.0.0 to 191.255.0.0</b>, and it can support up to 16,384 different networks, each with up to 65,534 hosts.
    Class C addresses are used for small networks and have a 24-bit network portion and an 8-bit host portion. The first three bits of a Class C address are always 110, and the range of Class C 
    addresses is from <b>192.0.0.0 to 223.255.255.0</b>, and it can support up to 2,097,152 different networks, each with up to 254 hosts.
    Class D addresses are used for multicasting and have a first byte in the range from 224 to 239. Class D addresses are not used for unicast communication. The range of Class D IP addresses 
    is <b>224.0.0.0 to 239.255.255.255</b>
    Class E addresses are reserved for experimental and research purposes and have a first byte in the range from 240 to 255. Class E addresses are also not used for unicast communication. The 
    range of Class E IP addresses is <b>240.0.0.0 to 255.255.255.254</b>
    <img src="images/2.5.classrange.jpg" alt="" width="19%" height="40%"> 
Classless Inter-Domain Routing (CIDR) is an IP addressing scheme that was introduced to address the limitations of the Hierarchical IP Addressing Scheme. CIDR allows for more flexible 
allocation of IP addresses and more efficient use of address space by allowing the creation of variable-length subnet masks (VLSM). In CIDR, the network prefix is not restricted to the 
predefined classes (A, B, C, etc.) of the Hierarchical IP Addressing Scheme. Instead, the network prefix can be any length, and the subnet mask is expressed as a number of bits, rather than 
a decimal number. For example, a CIDR notation of 192.168.1.0/24 indicates that the network prefix is 192.168.1.0, and the subnet mask is 24 bits long, which is equivalent to a decimal 
subnet mask of 255.255.255.0. The slash notation (/) means how many bits are turned on (1s). But keep in mind that the largest subnet mask available (regardless of the class of address) can only 
be a /30 because we have got to keep at least 2 bits for host bits.
Classless and classful are terms used to describe two different approaches for dividing up IP addresses for use on networks.
    Classful addressing was the original method of IP address assignment, which divided IP addresses into predefined classes (Class A, Class B, Class C, etc.) based on the number of network and 
    host bits in the address. Each class had a fixed number of bits reserved for the network and host portions of the address, and the network size was determined by the class. Classful addressing 
    provided a simple way to assign IP addresses and allocate network resources, but it had limitations. The size of the network had to be predetermined based on the class, which often resulted in 
    inefficient use of IP addresses. In classful addressing, the network portion of the IP address is determined by the class of the address, as follows:
        Class A addresses use the first octet to identify the network portion of the address, and the remaining three octets to identify the host portion.
        Class B addresses use the first two octets to identify the network portion of the address, and the remaining two octets to identify the host portion.
        Class C addresses use the first three octets to identify the network portion of the address, and the remaining octet to identify the host portion.
        Class D addresses are used for multicast traffic, and have a fixed network portion of the address (the first 4 bits are set to 1110).
        Class E addresses are reserved for experimental use, and have a fixed network portion of the address (the first 4 bits are set to 1111).
    Classless addressing, on the other hand, allows for more flexibility in IP address allocation. Instead of being restricted to predefined classes, the network administrator can choose the size of 
    the network by adjusting the number of bits used for the network portion of the address. This is commonly known as Variable Length Subnet Masking (VLSM). Classless addressing is more efficient and 
    flexible than classful addressing, and it is the current standard for IP address assignment. It allows for more efficient use of IP addresses and provides greater flexibility in designing and 
    managing IP networks.
Multicast traffic is a type of network traffic where a single message is sent to multiple recipients simultaneously. Some examples of applications that use multicast traffic include:
    Video conferencing: Video conferencing applications often use multicast traffic to transmit video and audio streams to multiple participants.
    IPTV: IPTV (Internet Protocol television) is a technology that allows television signals to be delivered over the internet. Multicast traffic is used to transmit the television signals to multiple 
    users at the same time.
    Online gaming: Many online gaming applications use multicast traffic to send game updates and other information to all players in a game.
    Stock market data: Stock market data providers often use multicast traffic to distribute real-time market data to subscribers.
    Distance learning: Distance learning applications use multicast traffic to stream educational content to multiple students in remote locations.
Private IP addresses allow devices within a private network to communicate with each other without needing a unique public IP address for each device. Instead, a single public IP address is 
used to represent the entire private network on the internet, and network address translation (NAT) is used to translate between the private IP addresses and the public IP address when data 
is sent to or received from the internet. NAT, is a technology used to enable devices on a private network to communicate with the internet using a single public IP address. In a network 
using NAT, the private IP addresses of devices on the network are not visible on the internet. 
    When a device on the network sends data to the internet, the NAT device (typically a router) replaces the private IP address of the sending device with the public IP address of the router
    When data is sent back to the router's public IP address, the NAT device translates the public IP address back into the private IP address of the device that requested the data, and forwards 
    the data to that device.
A typical NAT table entry contains the following information:
    Source IP address: The private IP address of the device that initiated the request.
    Source port number: The dynamically assigned port number used by the device for the request.
    Destination IP address: The IP address of the destination server that the request was sent to.
    Destination port number: The port number used by the destination server for the service requested.
    NAT IP address: The public IP address assigned to the NAT device.
    NAT port number: The dynamically assigned port number used by the NAT device to forward the request to the destination server.
    Timeout value: The amount of time that the NAT table entry will remain active before being removed.
    <img src="images/7.1.NATtable.jpg" alt="" width="49%" height="40%">
There are several types of NAT devices available, including:
    Home routers     
    Firewall appliances
    Software-based NAT
    Load balancers
3 types of communication in computer networks, including the Internet
    Unicast refers to a one-to-one communication model, where a single sender transmits data to a single receiver. In this type of communication, the data is sent from one source to a specific 
    destination IP address, and only the intended recipient receives and processes the data.
    Multicast, on the other hand, refers to a one-to-many communication model, where a single sender transmits data to multiple recipients simultaneously. In multicast communication, the data 
    is sent from one source to a specific multicast group address, and any host that has joined that group will receive the data.
    Broadcast is a one-to-all communication model, where a single sender transmits data to all hosts on a network. In broadcast communication, the data is sent from one source to a special 
    broadcast address, and all hosts on the network receive and process the data.
IPv6, or Internet Protocol version 6, is the latest version of the Internet Protocol (IP) that is designed to replace IPv4. IPv6 provides a larger address space than IPv4, which is critical for 
the continued growth of the Internet and the increasing number of devices that are connected to it. There are several benefits of IPv6 over IPv4, including:    
    Larger address space: IPv6 uses 128-bit addresses, providing a much larger address space than the 32-bit addresses used in IPv4. This allows for more unique IP addresses to be assigned, which 
    is critical for the growth of the Internet.    
    Auto-configuration: IPv6 includes features for automatic address configuration, making it easier to configure devices on a network. In IPv6, there is a mechanism called stateless address 
    auto configuration (SLAAC) that allows devices to configure their own IPv6 addresses without the need for a DHCPv6 server. With SLAAC, a device uses information advertised by a router to 
    generate its own IPv6 address. The process works as follows:
        The router sends out a Router Advertisement (RA) message periodically, which contains information such as the prefix of the network and other configuration details.
        When a device receives the RA message, it generates its own IPv6 address by combining the network prefix with its interface identifier. The interface identifier can be generated using 
        a variety of methods, such as using the device's MAC address or a random number.
        The device then tests its newly generated address to make sure it is unique on the network.
        If the address is unique, the device can start using it to communicate on the network.    
    Improved security: IPv6 includes built-in security features such as IPsec, which can help to secure network traffic.    
    Better performance: IPv6 includes features such as multicast, which can help to reduce network traffic and improve performance.
IPv6 addressing uses hexadecimal notation, which includes digits from 0 to 9 and letters from A to F. An IPv6 address is 128 bits long and is represented as eight groups of four hexadecimal 
digits, separated by colons. For example, the following is a valid IPv6 address: 
    2001:0db8:85a3:0000:0000:8a2e:0370:7334
IPv6 also allows for shortened expressions, where leading zeros can be omitted, and consecutive groups of zeros can be replaced with a double colon (::). For example, the previous IPv6 address 
can be expressed as:
    2001:db8:85a3::8a2e:370:7334
IPv6 has several types of addresses, including unicast, multicast, and anycast addresses. There are also several special addresses in IPv6, including:
    Loopback address: This address (::1) is used to send traffic to the same interface that sent the traffic.
    Unspecified address: This address (::) is used to indicate an unknown or unspecified address.
    Link-local address: This address (fe80::/10) is used for communication between devices on the same physical network.
    Site-local address: This address (fec0::/10) was deprecated in favor of Unique Local Addresses (ULAs), which are used for communication within a site or organization.
    Multicast addresses: As mentioned earlier, multicast addresses are used to send data to multiple interfaces. The range of multicast addresses in IPv6 is 224.0.0.0 to 239.255.255.255.
In the example, "fe80::/10", the "/10" indicates that the first 10 bits of the IPv6 address are used to identify the network, and the remaining bits are used to identify the host. This means that 
the address range represented by "fe80::/10" includes all addresses that start with the binary value "1111 1110 10" in the first 10 bits.
Anycast configuration, multiple devices or servers are assigned the same IP address, but each device is located at a different location on the network. When a client sends a request to an anycast 
address, the request is sent to the nearest device on the network that is configured to receive traffic for that address. This can help to improve network efficiency, reduce latency, and improve 
the reliability of network services. Anycast addressing is commonly used in large-scale networks, such as content delivery networks (CDNs), where multiple servers can be used to deliver content 
to users around the world. By using anycast addressing, CDNs can route traffic to the server that is closest to the user, helping to reduce latency and improve the user experience.
<b id="id_ip_subnetting_details" style="color: rgb(0, 0, 0); text-decoration: none;">IP Subnetting, Troubleshooting IP</b>
Subnetting is the process of dividing a larger network into smaller subnets by borrowing bits from the host ID portion of the IP address. The purpose of subnetting is to improve the efficiency of 
network resources and to manage network traffic in a more organized and secure manner. When a network is subnetted, it is divided into multiple smaller networks, each with its own unique network 
address. This allows for better management of network traffic and reduces the amount of unnecessary broadcast traffic that can slow down a network. It also provides better security by isolating 
traffic within each subnet, making it more difficult for unauthorized users to gain access to sensitive information. Subnetting also allows for more efficient use of IP addresses, as it enables 
an organization to assign IP addresses to devices only as needed, rather than wasting them on unused or unnecessary addresses. This can be particularly important for larger networks, as it allows 
for the conservation of IP address space, which can be a limited resource. Overall, subnetting is an important tool for network administrators, as it helps to optimize network performance, improve 
security, and conserve IP address space. To create subnets, you would generally follow these steps:
    Determine the number of required subnets: The number of subnets required depends on the size of the network and the number of devices that need to be connected to it.
    Choose a suitable subnet mask: The subnet mask determines the size of each subnet and the number of host addresses available on each subnet. The most commonly used subnet masks 
    are /24 (255.255.255.0 or 1111 1111.1111 1111.1111 1111.0000 0000), /25 (255.255.255.128 or 1111 1111.1111 1111.1111 1111.1000 0000), /26 (255.255.255.192 or 1111 1111.1111 1111.1111 
    1111.1100 0000), and /27 (255.255.255.224 or 1111 1111.1111 1111.1111 1111.1110 0000).
    Determine the network address: The network address is the IP address that identifies the subnet. It is obtained by applying the subnet mask to the IP address of the network.
    Determine the broadcast address: The broadcast address is the IP address that is used to send messages to all devices on the subnet. It is obtained by setting all host bits to 1 in the subnet 
    mask and adding the result to the network address.
    Determine the range of valid host addresses: The range of valid host addresses is the range of IP addresses that can be assigned to devices on the subnet. It is obtained by taking the network 
    address and adding 1 to it to obtain the first valid host address, and subtracting 1 from the broadcast address to obtain the last valid host address.
    Assign IP addresses to devices: Once the subnet has been created, IP addresses can be assigned to devices on the subnet based on the range of valid host addresses.
    <img src="images/8.1.subnettingguideline.jpg" alt="" width="59%" height="40%">
We need to borrow 2 bits from the host portion of the address to create 4 subnets because 2 bits can represent 4 different combinations of 0s and 1s. Borrowing 1 bit creates 2 subnets, borrowing 3 
bits creates 8 subnets, borrowing 4 bits creates 16 subnets and so on. An example to create 7 subnets from the current network ID, 192.168.4.0/24. List each newly created Network ID, Subnet mask, 
Host ID range, # of hosts, # of usable hosts and Broadcast ID.  
<img src="images/8.2.subnettingexample.jpg" alt="" width="39%" height="40%">
A subnet mask is a 32-bit value that is used to divide an IP address into two parts, a network address and a host address. The subnet mask works in conjunction with the IP address to determine which 
part of the address represents the network and which part represents the host. The subnet mask consists of a series of 1's followed by a series of 0's. The number of 1's in the subnet mask determines 
how many bits are used for the network portion of the address, and the number of 0's determines how many bits are used for the host portion. For example, a subnet mask of 255.255.255.0 (or /24 in CIDR 
notation) means that the first 24 bits of the IP address are used to identify the network, and the remaining 8 bits are used to identify the host. This allows the network administrator to create multiple 
subnets within a larger network, each with its own unique network address.
FLSM (Fixed-Length Subnet Mask), Fixed Length Subnetting is a technique used in computer networking to divide an IP address block into multiple subnets of the same size. In fixed length subnetting, each 
subnet has the same number of hosts or addresses, which is predetermined before the subnetting process begins. This technique is also known as FLSM (Fixed-Length Subnet Mask) or traditional subnetting.
VLSM (Variable Length Subnet Masking) is a technique used in subnetting where the subnet mask used for a network can vary in length, allowing for more efficient use of IP address space. This is also 
called subnetting a subnet. 
Example, current IP addressing is 121.37.10.0/26 and we need to subnet this network with 30 hosts on first subnet, 20 on second subnet, 10 on third subnet, 2 on three other subnet. please list the 
subnet IP range in FLSM method
<img src="images/8.3.subnettingexampleforFLSMVLSM.jpg" alt="" width="29%" height="40%">     <img src="images/8.4.subnettingexampleforFLSMVLSMdata.jpg" alt="" width="59%" height="40%">
My subnet mask is /25 , is it possible to assign a device with the IP of 192.168.1.130. No, The network address for your subnet would be 192.168.1.0, with a broadcast address of 192.168.1.127. Therefore, 
the range of available host addresses for your subnet would be from 192.168.1.1 to 192.168.1.126. Since 192.168.1.130 is outside of this range, it cannot be assigned to a device on your network without 
changing the subnet mask to include a larger range of available host addresses. If you need to use the IP address 192.168.1.130, you would need to change the subnet mask to at least /24 or lower, which 
would provide a range of 256 available host addresses.
After the netmask 255.255.255.0, there are several possible netmasks that can be used to define the network and host portions of an IP address. Some examples include:
    255.255.255.128: defines a network with 128 hosts, where the first 25 bits of the IP address are used to define the network portion, and the remaining 7 bits are used to define the host portion.
    255.255.255.192: defines a network with 64 hosts, where the first 26 bits of the IP address are used to define the network portion, and the remaining 6 bits are used to define the host portion.
    255.255.255.224: defines a network with 32 hosts, where the first 27 bits of the IP address are used to define the network portion, and the remaining 5 bits are used to define the host portion.
    255.255.255.240: defines a network with 16 hosts, where the first 28 bits of the IP address are used to define the network portion, and the remaining 4 bits are used to define the host portion.
    255.255.255.248: defines a network with 8 hosts, where the first 29 bits of the IP address are used to define the network portion, and the remaining 3 bits are used to define the host portion.
    255.255.255.252: defines a network with 2 hosts, where the first 30 bits of the IP address are used to define the network portion, and the remaining 2 bits are used to define the host portion.
Each octet can have value from 0 to 255. If a network mask is 255.255.248.0 and given IP addresses are 192.168.40.10 or 192.168.41.10 then what are the network IDs 
    In 192.168.40.10 the network bit is 192.168.40 and host bit is .10 
    In 192.168.41.10 the network bit is 192.168.40 and host bit is 1.10 
<b id="id_troubleshooting_ip_addressing_details" style="color: rgb(0, 0, 0); text-decoration: none;">Troubleshooting IP Addressing</b>
Here are some basic network troubleshooting steps you can follow:
    Check Physical Connections: Make sure all cables are plugged in properly and that the device is connected to the right port.
    Check Network Settings: Verify that the device has the correct IP address, subnet mask, default gateway, and DNS server settings.
    Ping Test: Use the ping command to test connectivity to other devices on the network. Ping the IP address of the device you are trying to connect to and see if you get a response.
        Pinging the loopback address(ping 127.0.0.1), this is the diagnostic, if you get a successful ping, your IP stack is considered to be initialized. If it fails, then you have an IP stack 
        failure and need to reinstall TCP/IP on the host.
        Pinging local host IP, if that’s successful, your Network Interface Card (NIC) is functioning. If it fails, there is a problem with the NIC. Success here doesn’t mean that a cable is 
        plugged into the NIC, only that the IP protocol stack on the host can communicate to the NIC (via the LAN driver).
        Pinging the default gateway (router), if the ping works, it means that the NIC is plugged into the network and can communicate on the local network. If it fails, you have a local physical 
        network problem that could be anywhere from the NIC to the router.
        Pinging a remote server. if that works, then you know that you have IP communication between the local host and the remote server
    Check Firewall Settings: If you have a firewall enabled, make sure that it is not blocking the traffic you need to pass.
    Check for Network Congestion: Run a network performance test to see if there is any congestion or packet loss on the network.
    Check DNS Settings: Ensure that DNS is working correctly by pinging a domain name and seeing if it resolves to an IP address.
    Reboot: Sometimes the simplest solution is to reboot the device, as this can clear any temporary issues.
    Update Firmware and Drivers: Check for updates to firmware and drivers for the device you are troubleshooting.
Ping is a command-line tool that sends a small packet of data to a specific IP address or domain name and waits for a response. The tool measures the time it takes for the packet to travel from 
the sender to the receiver and back again. If a response is received, the tool reports the response time and whether the packet was successfully received. Ping is useful for testing network 
connectivity and identifying network latency or packet loss issues.
Traceroute is another command-line tool that is used to trace the path that packets take from the sender to the receiver. Traceroute sends packets with increasing time-to-live (TTL) values to the 
destination IP address. As the packets travel through each router in the path, the router decrements the TTL value and sends an error message back to the sender when the TTL reaches zero. The sender 
uses these error messages to identify each router in the path and measure the time it takes for packets to travel between each router. Traceroute can be useful for identifying network bottlenecks 
and routing issues.
<b id="id_network_address_translation_details" style="color: rgb(0, 0, 0); text-decoration: none;">Network Address Translation (NAT)</b>
NAT allows many private IP addresses to be represented by a small number of public IP addresses, thus slowing down IP address depletion. Typically NAT is configured on the border router (Corporate 
router)
<img src="images/8.5.NATconfiguration.jpg" alt="" width="29%" height="40%">
There are three types of Network Address Translation (NAT):
Static NAT: One to One, Static NAT maps a single, public IP address to a single, private IP address. It's commonly used for servers that need to be accessible from the Internet, such as web servers or email 
servers. With static NAT, the public IP address is permanently assigned to the private IP address, and incoming traffic is always directed to that IP address.
<img src="images/8.6.1.StaticNAT.jpg" alt="" width="19%" height="40%">
Dynamic NAT: Many to Many, Dynamic NAT maps a pool of public IP addresses to a pool of private IP addresses. When a private IP address requests access to the Internet, it is assigned an available public 
IP address from the pool. This is useful for networks with a large number of devices, as it allows them to share a smaller pool of public IP addresses.
<img src="images/8.6.2.DynamicNAT.jpg" alt="" width="19%" height="40%">
Port Address Translation (PAT): Many to One with ports, Port Address Translation, also known as Network Address and Port Translation (NAPT), is a variation of dynamic NAT that maps multiple private IP 
addresses to a single, public IP address by using different ports. With PAT, each private IP address is assigned a unique port number, which is combined with the public IP address to create a unique 
identifier for incoming traffic. PAT is commonly used in home and small business networks where only one public IP address is available.
<img src="images/8.6.3.PortNAT.jpg" alt="" width="19%" height="40%">
In the context of Network Address Translation (NAT), there are four terms commonly used to describe different types of IP addresses involved in the translation process. These terms are:
    Inside local: This is the IP address of a device on your internal network that you want to communicate with devices on the internet.
    Inside global: This is the IP address that the device on your internal network uses to communicate with devices on the internet. It is assigned by the router or NAT device that connects your internal 
    network to the internet.
    Outside local: This is the IP address of a device on the internet that you want to communicate with from your internal network.
    Outside global: This is the IP address that the device on the internet uses to communicate with devices on your internal network. It is assigned by the router or NAT device that connects your internal 
    network to the internet.
    <img src="images/8.7.1.NATNames.jpg" alt="" width="29%" height="40%">      <img src="images/8.7.2.NATNames.jpg" alt="" width="29%" height="40%">     
<b id="id_ip_routing_details" style="color: rgb(0, 0, 0); text-decoration: none;">IP Routing</b>

<b><a href="#id_top_details" style="color: rgb(0, 0, 0); text-decoration: none;">######   reach start of the document   ######</a></b>  
https://media.oiipdf.com/pdf/214dd702-0ee6-4e47-b336-fce0d95934a5.pdf <b>reffered book online</b>
<img src="images/xxxx.xxxx.xxxx.xxxx.jpg" alt="" width="49%" height="40%"> 
<b id="id_last_details"></b>
<hr>
</pre>
</body>
</html>